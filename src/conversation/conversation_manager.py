"""å¯¹è¯ç®¡ç†å™¨ - æ ¸å¿ƒç¼–æ’å™¨."""

from datetime import datetime
from typing import List, Optional, Tuple

from src.models import MemoryFragment
from src.retrieval.memory_retriever import MemoryRetriever, RetrievalConfig
from src.storage.memory_storage import MemoryStorage
from src.storage.session_manager import SessionManager
from src.storage.user_manager import UserManager
from src.utils.glm_client import GLMClient


class ConversationManager:
    """
    å¯¹è¯ç®¡ç†å™¨ - è®°å¿†å¢å¼ºçš„å¯¹è¯ç³»ç»Ÿ

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ç®¡ç†å¯¹è¯çŠ¶æ€å’Œæ¶ˆæ¯å†å²
    2. å®æ—¶è®°å¿†æå–ï¼ˆå‘¨æœŸæ€§æˆ–è¾¾åˆ°é˜ˆå€¼ï¼‰
    3. è¯­ä¹‰æ£€ç´¢ç›¸å…³è®°å¿†
    4. å°†è®°å¿†æ³¨å…¥åˆ° Prompt
    5. ç”Ÿæˆä¸ªæ€§åŒ–å›å¤

    è®¾è®¡åŸåˆ™ï¼š
    - é™ªä¼´å‹ AI ä¼˜å…ˆï¼šæƒ…æ„Ÿè¿æ¥ã€ä¸ªæ€§åŒ–ã€å…³ç³»æ·±åº¦
    - ä¸Šä¸‹æ–‡èŠ‚çº¦ï¼šåªæ£€ç´¢å’Œæ³¨å…¥æœ€ç›¸å…³çš„è®°å¿†
    - å®æ—¶å“åº”ï¼šè®°å¿†æå–ä¸åº”é˜»å¡å¯¹è¯
    """

    def __init__(
        self,
        user_manager: UserManager,
        session_manager: SessionManager,
        memory_storage: MemoryStorage,
        glm_client: GLMClient,
        retrieval_config: Optional[RetrievalConfig] = None,
        memory_extract_threshold: int = 5,  # æ¯Nè½®æ¶ˆæ¯æå–ä¸€æ¬¡è®°å¿†
        max_context_memories: int = 5,  # æ³¨å…¥åˆ°ä¸Šä¸‹æ–‡çš„æœ€å¤§è®°å¿†æ•°
    ):
        """
        åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨

        Args:
            user_manager: ç”¨æˆ·ç®¡ç†å™¨
            session_manager: ä¼šè¯ç®¡ç†å™¨
            memory_storage: è®°å¿†å­˜å‚¨
            glm_client: GLM-4 å®¢æˆ·ç«¯
            retrieval_config: æ£€ç´¢é…ç½®
            memory_extract_threshold: è®°å¿†æå–é˜ˆå€¼ï¼ˆè½®æ•°ï¼‰
            max_context_memories: æœ€å¤§ä¸Šä¸‹æ–‡è®°å¿†æ•°
        """
        self.user_manager = user_manager
        self.session_manager = session_manager
        self.memory_storage = memory_storage
        self.glm_client = glm_client
        self.retriever = MemoryRetriever(memory_storage, retrieval_config)
        self.memory_extract_threshold = memory_extract_threshold
        self.max_context_memories = max_context_memories

        # æ¶ˆæ¯ç¼“å†²åŒºï¼ˆä¸´æ—¶å­˜å‚¨å½“å‰ä¼šè¯çš„æ¶ˆæ¯ï¼‰
        self._message_buffers: dict = {}

    def chat(
        self,
        user_id: str,
        session_id: str,
        user_message: str,
        extract_now: bool = False,
    ) -> str:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            extract_now: æ˜¯å¦ç«‹å³æå–è®°å¿†ï¼ˆé»˜è®¤ Falseï¼Œè¾¾åˆ°é˜ˆå€¼æ—¶è‡ªåŠ¨æå–ï¼‰

        Returns:
            AI å›å¤
        """
        # 1. å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯åˆ°ç¼“å†²åŒº
        self._add_message_to_buffer(session_id, "user", user_message)

        # 2. æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = self.retriever.retrieve(
            user_id=user_id,
            session_id=session_id,
            query=user_message,
            config=RetrievalConfig(
                top_k=self.max_context_memories, min_importance=5
            ),  # åªæ£€ç´¢é‡è¦è®°å¿†ï¼ˆ5åˆ†åŠä»¥ä¸Šï¼‰
        )

        # 3. æ„å»ºå¸¦è®°å¿†çš„ Prompt
        prompt = self._build_prompt_with_memories(
            user_message=user_message, memories=relevant_memories
        )

        # 4. è°ƒç”¨ GLM-4 ç”Ÿæˆå›å¤
        ai_response = self._generate_response(prompt)

        # 5. å­˜å‚¨åŠ©æ‰‹æ¶ˆæ¯åˆ°ç¼“å†²åŒº
        self._add_message_to_buffer(session_id, "assistant", ai_response)

        # 6. æ£€æŸ¥æ˜¯å¦éœ€è¦æå–è®°å¿†ï¼ˆåœ¨å®Œæ•´å¯¹è¯è½®æ¬¡ä¹‹åï¼‰
        message_count = len(self._message_buffers.get(session_id, []))
        print(f"ğŸ” [è°ƒè¯•] æ¶ˆæ¯æ•°: {message_count}, æå–é˜ˆå€¼: {self.memory_extract_threshold}")
        should_extract = extract_now or (
            message_count % self.memory_extract_threshold == 0
        )
        print(f"ğŸ” [è°ƒè¯•] æ˜¯å¦æå–: {should_extract} (extract_now={extract_now}, å–ä½™={message_count % self.memory_extract_threshold})")

        if should_extract:
            self._extract_and_store_memories(user_id, session_id)

        # 7. æ›´æ–°ä¼šè¯ç»Ÿè®¡
        self.session_manager.update_session(
            session_id, message_count=message_count
        )

        return ai_response

    def _add_message_to_buffer(self, session_id: str, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°ç¼“å†²åŒº"""
        if session_id not in self._message_buffers:
            self._message_buffers[session_id] = []

        self._message_buffers[session_id].append(
            {"role": role, "content": content, "timestamp": datetime.now().isoformat()}
        )

    def _extract_and_store_memories(self, user_id: str, session_id: str):
        """ä»æ¶ˆæ¯ç¼“å†²åŒºæå–è®°å¿†å¹¶å­˜å‚¨"""
        if session_id not in self._message_buffers:
            print(f"âš ï¸  ä¼šè¯ {session_id} ä¸åœ¨ç¼“å†²åŒº")
            return

        messages = self._message_buffers[session_id]
        if not messages:
            print(f"âš ï¸  ä¼šè¯ {session_id} æ²¡æœ‰æ¶ˆæ¯")
            return

        print(f"\nğŸ” æå–è®°å¿†... (å½“å‰ {len(messages)} æ¡æ¶ˆæ¯)")

        # 1. æ‹¼æ¥å¯¹è¯æ–‡æœ¬
        conversation = "\n".join(
            [f"{msg['role']}: {msg['content']}" for msg in messages]
        )

        # 2. è°ƒç”¨ GLM-4 æå–è®°å¿†
        try:
            print("ğŸ“ è°ƒç”¨ GLM-4 API æå–è®°å¿†...")
            fragments_data = self.glm_client.extract_memory_with_scoring(conversation)
            print(f"ğŸ“¦ æå–åˆ° {len(fragments_data)} ä¸ªç‰‡æ®µ")

            # 3. è¿‡æ»¤å’Œè½¬æ¢ï¼ˆåŒºåˆ† user å’Œ assistantï¼‰
            fragments = []
            for frag_data in fragments_data:
                content = frag_data["content"].strip()
                speaker = frag_data.get("speaker", "user")  # è·å– speaker å­—æ®µï¼Œé»˜è®¤ user

                # æ ¹æ®ä¸åŒçš„ speaker åº”ç”¨ä¸åŒçš„è¿‡æ»¤è§„åˆ™
                if speaker == "assistant":
                    # Assistant çš„è¿‡æ»¤è§„åˆ™ï¼šåªè¿‡æ»¤æ‰æ˜æ˜¾æ— ä»·å€¼çš„å†…å®¹
                    # è¿‡æ»¤é—®é¢˜ï¼ˆAI çš„é—®é¢˜ä¸æ˜¯è®°å¿†ï¼‰
                    if self._is_question(content):
                        print(f"   âš ï¸  [Assistant] è¿‡æ»¤é—®é¢˜: {content[:40]}...")
                        continue

                    # è¿‡æ»¤ç®€å•çš„ç¡®è®¤/å¯’æš„ï¼ˆè¯„åˆ†ä¼šå¾ˆä½ï¼Œä½†è¿™é‡Œå¯ä»¥æå‰è¿‡æ»¤ï¼‰
                    if content in ["å¥½çš„", "æ²¡é—®é¢˜", "æˆ‘æ˜ç™½äº†", "å—¯å—¯", "æ”¶åˆ°", "ä½ å¥½", "æ‚¨å¥½"]:
                        print(f"   âš ï¸  [Assistant] è¿‡æ»¤ç®€å•ç¡®è®¤: {content[:40]}...")
                        continue

                elif speaker == "user":
                    # User çš„è¿‡æ»¤è§„åˆ™ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
                    # è¿‡æ»¤é—®é¢˜ï¼ˆé—®å¥ä¸æ˜¯è®°å¿†ï¼‰
                    if self._is_question(content):
                        print(f"   âš ï¸  [User] è¿‡æ»¤é—®é¢˜ï¼ˆä¸æ˜¯é™ˆè¿°ï¼‰: {content[:40]}...")
                        continue

                    # åªä¿ç•™ç¬¬ä¸€äººç§°é™ˆè¿°ï¼ˆç”¨æˆ·è¯´çš„è¯ï¼‰
                    if not self._is_first_person_statement(content):
                        print(f"   âš ï¸  [User] è¿‡æ»¤éç¬¬ä¸€äººç§°é™ˆè¿°: {content[:40]}...")
                        continue

                importance_score = frag_data["importance_score"]

                # ç‰¹æ®Šè§„åˆ™ï¼šèº«ä»½ä¿¡æ¯ï¼ˆå§“åã€èŒä¸šï¼‰å¼ºåˆ¶æå‡åˆ° 5 åˆ†ï¼ˆä»…å¯¹ userï¼‰
                if speaker == "user" and self._is_identity_info(content):
                    original_score = importance_score
                    importance_score = max(importance_score, 5)
                    if original_score < 5:
                        print(f"   â­ [User] èº«ä»½ä¿¡æ¯æå‡åˆ†æ•°: {original_score} â†’ {importance_score}")

                # â­ ç‰¹æ®Šè§„åˆ™ï¼šAI å…³é”®è¯æ£€æµ‹å’Œåˆ†æ•°æå‡ï¼ˆä»…å¯¹ assistantï¼‰
                if speaker == "assistant":
                    original_score = importance_score
                    # æ£€æµ‹é‡è¦å…³é”®è¯å¹¶æå‡åˆ†æ•°
                    importance_score = max(importance_score, self._boost_assistant_score(content))
                    if importance_score > original_score:
                        print(f"   â­ [Assistant] å…³é”®è¯æå‡åˆ†æ•°: {original_score} â†’ {importance_score}")

                # â­ ç‰¹æ®Šè§„åˆ™ï¼šæ£€æµ‹ç”¨æˆ·æ˜¯å¦åœ¨å¼•ç”¨ AI çš„è¯ï¼ˆä»…å¯¹ userï¼‰
                if speaker == "user" and self._is_user_referencing_assistant(content):
                    # ç”¨æˆ·å¼•ç”¨ AI çš„è¯ï¼Œè¯´æ˜è¿™ä¸ªå†…å®¹å¾ˆé‡è¦ï¼Œéœ€è¦è®°å½•
                    original_score = importance_score
                    importance_score = max(importance_score, 7)  # è‡³å°‘ 7 åˆ†
                    if importance_score > original_score:
                        print(f"   â­ [User] å¼•ç”¨ AI çš„è¯ï¼Œæå‡åˆ†æ•°: {original_score} â†’ {importance_score}")
                        # åœ¨ metadata ä¸­æ ‡è®°è¿™æ˜¯å¼•ç”¨
                        frag_data["_is_reference"] = True

                fragment = MemoryFragment(
                    content=content,
                    timestamp=datetime.now(),
                    speaker=speaker,  # â­ æ·»åŠ  speaker å­—æ®µ
                    type=frag_data["type"],
                    entities=[],  # å¯ä»¥åç»­è¡¥å……
                    topics=[],
                    sentiment=frag_data["sentiment"],
                    importance_score=importance_score,
                    confidence=0.8,
                    metadata={"reasoning": frag_data.get("reasoning", "")},
                )
                fragments.append(fragment)
                print(f"   âœ… [{speaker}] ä¿ç•™è®°å¿†: {content[:40]}... (åˆ†æ•°: {importance_score}/10)")

            # 4. å»é‡æ£€æŸ¥
            unique_fragments = []
            seen_contents = set()

            for fragment in fragments:
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸ä¼¼çš„è®°å¿†
                is_duplicate = False

                # ä¸æœ¬æ¬¡æå–çš„å…¶ä»–è®°å¿†æ¯”è¾ƒ
                for existing in unique_fragments:
                    if self._are_similar_fragments(fragment.content, existing.content):
                        print(f"   âš ï¸  å»é‡: {fragment.content[:40]}...")
                        is_duplicate = True
                        break

                # ä¸å·²å­˜å‚¨çš„è®°å¿†æ¯”è¾ƒï¼ˆä»…æ£€æŸ¥å‰5æ¡ï¼Œé¿å…è¿‡å¤šæŸ¥è¯¢ï¼‰
                if not is_duplicate:
                    try:
                        existing_memories = self.retriever.retrieve(
                            user_id=user_id,
                            session_id=session_id,
                            query=fragment.content,
                            config=RetrievalConfig(top_k=5, min_importance=0, score_threshold=0)
                        )
                        for existing_fragment, _ in existing_memories:
                            if self._are_similar_fragments(fragment.content, existing_fragment.content):
                                print(f"   âš ï¸  å»é‡ï¼ˆå·²å­˜å‚¨ï¼‰: {fragment.content[:40]}...")
                                is_duplicate = True
                                break
                    except Exception as e:
                        print(f"   âš ï¸  å»é‡æ£€æŸ¥å¤±è´¥: {e}")

                if not is_duplicate:
                    unique_fragments.append(fragment)

            # 5. æŒ‰ä¸åŒé˜ˆå€¼è¿‡æ»¤ï¼ˆuser: 5åˆ†ï¼Œassistant: 3åˆ†ï¼‰
            important_fragments = []
            filtered_fragments = []

            for f in unique_fragments:
                # æ ¹æ® speaker ä½¿ç”¨ä¸åŒçš„é˜ˆå€¼
                if f.speaker == "assistant":
                    threshold = 3  # Assistant ç”¨ 3 åˆ†é˜ˆå€¼
                else:  # user
                    threshold = 5  # User ç”¨ 5 åˆ†é˜ˆå€¼

                if f.importance_score >= threshold:
                    important_fragments.append(f)
                else:
                    filtered_fragments.append((f, threshold))

            # æ‰“å°è¢«è¿‡æ»¤æ‰çš„è®°å¿†ï¼ˆè°ƒè¯•ç”¨ï¼‰
            if filtered_fragments:
                print(f"   âš ï¸  å› åˆ†æ•°è¿‡ä½è¢«è¿‡æ»¤:")
                for f, threshold in filtered_fragments:
                    print(f"      [{f.speaker}] {f.importance_score}/10 (é˜ˆå€¼: {threshold}) {f.content[:40]}...")

            if important_fragments:
                memory_ids = self.memory_storage.store_memories(
                    user_id=user_id, session_id=session_id, fragments=important_fragments
                )
                print(f"âœ… å­˜å‚¨äº† {len(memory_ids)} æ¡è®°å¿†")
                for f in important_fragments:
                    print(f"   [{f.speaker}] [{f.importance_score}/10] {f.content[:40]}...")

        except Exception as e:
            print(f"âš ï¸  è®°å¿†æå–å¤±è´¥: {e}")

    def _build_prompt_with_memories(
        self, user_message: str, memories: List[Tuple[MemoryFragment, float]]
    ) -> str:
        """
        æ„å»ºå¸¦è®°å¿†çš„ Prompt

        è®¾è®¡è¦ç‚¹ï¼š
        1. è®°å¿†ä¼˜å…ˆçº§ï¼šæŒ‰ç›¸å…³æ€§æ’åº
        2. è®°å¿†æ•°é‡æ§åˆ¶ï¼šé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
        3. é™ªä¼´å‹ä¼˜åŒ–ï¼šå¼ºè°ƒæƒ…æ„Ÿè¿æ¥ã€ä¸ªæ€§åŒ–
        4. â­ åŒºåˆ†è¯´è¯è€…ï¼šè®© AI çŸ¥é“å“ªäº›æ˜¯ç”¨æˆ·è¯´çš„ï¼Œå“ªäº›æ˜¯è‡ªå·±è¯´çš„
        """

        # è®°å¿†éƒ¨åˆ†ï¼ˆåŒºåˆ† user å’Œ assistantï¼‰
        if memories:
            user_memories = []
            assistant_memories = []

            for fragment, score in memories:
                memory_str = (
                    f"- [{fragment.importance_score}/10] {fragment.content} "
                    f"(ç±»å‹: {fragment.type}, æƒ…æ„Ÿ: {fragment.sentiment})"
                )

                if fragment.speaker == "assistant":
                    assistant_memories.append(memory_str)
                else:  # user
                    user_memories.append(memory_str)

            # æ„å»ºè®°å¿†æ–‡æœ¬
            memory_blocks = []

            if user_memories:
                memory_blocks.append("### ğŸ‘¤ ç”¨æˆ·è¯´è¿‡çš„è¯:")
                memory_blocks.extend(user_memories)
                memory_blocks.append("")  # ç©ºè¡Œ

            if assistant_memories:
                memory_blocks.append("### ğŸ¤– ä½ ä¹‹å‰è¯´è¿‡çš„é‡è¦è¯ï¼ˆæ‰¿è¯ºã€å»ºè®®ã€æ”¯æŒï¼‰:")
                memory_blocks.append("â­ **è¯·ç‰¹åˆ«æ³¨æ„ï¼šè¿™äº›æ˜¯ä½ ä¹‹å‰çš„æ‰¿è¯ºå’Œå»ºè®®ï¼Œè¯·å°½é‡éµå®ˆå’Œå»¶ç»­**")
                memory_blocks.extend(assistant_memories)

            memories_text = "\n".join(memory_blocks)
        else:
            memories_text = "ï¼ˆè¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œè¿˜æ²¡æœ‰å…³äºä½ çš„è®°å¿†ï¼‰"

        # æ„å»ºå®Œæ•´çš„ Promptï¼ˆä¸­æ–‡å‹å¥½ã€é™ªä¼´å‹ä¼˜åŒ–ï¼‰
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€è´´å¿ƒçš„é™ªä¼´å‹ AI åŠ©æ‰‹ã€‚

## é‡è¦è®°å¿†

è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹è®°å¿†ï¼Œåœ¨å›å¤ä¸­ä½“ç°ä½ çš„ç†è§£ï¼š

{memories_text}

## å¯¹è¯åŸåˆ™

1. **æƒ…æ„Ÿè¿æ¥ä¼˜å…ˆ**ï¼šå…³æ³¨ç”¨æˆ·çš„æƒ…æ„ŸçŠ¶æ€ï¼Œç»™äºˆæ¸©æš–å’Œæ”¯æŒ
2. **ä¸ªæ€§åŒ–å›å¤**ï¼šæ ¹æ®è®°å¿†ä¸­çš„ä¿¡æ¯ï¼Œæä¾›ä¸ªæ€§åŒ–çš„å›åº”
3. **â­ ä¿¡å®ˆæ‰¿è¯º**ï¼šå¦‚æœä½ ä¹‹å‰åšè¿‡æ‰¿è¯ºæˆ–çº¦å®šï¼Œè¯·è®°ä½å¹¶éµå®ˆ
4. **â­ å»¶ç»­å»ºè®®**ï¼šå¦‚æœä½ ä¹‹å‰ç»™è¿‡å»ºè®®ï¼Œå¯ä»¥é€‚å½“è·Ÿè¿›å’Œå…³å¿ƒ
5. **è‡ªç„¶å¯¹è¯**ï¼šåƒæœ‹å‹ä¸€æ ·è‡ªç„¶äº¤æµï¼Œä¸è¦åˆ»æ„æåŠè®°å¿†
6. **å°Šé‡è¾¹ç•Œ**ï¼šå¯¹äºæ•æ„Ÿè¯é¢˜ä¿æŒå°Šé‡å’Œè°¨æ…
7. **ä¸­æ–‡è¡¨è¾¾**ï¼šä½¿ç”¨è‡ªç„¶ã€æ¸©æš–çš„ä¸­æ–‡è¡¨è¾¾

## å½“å‰å¯¹è¯

ç”¨æˆ·è¯´ï¼š{user_message}

è¯·åŸºäºè®°å¿†å’Œå¯¹è¯åŸåˆ™ï¼Œç»™å‡ºæ¸©æš–ã€è´´å¿ƒçš„å›å¤ï¼š"""

        return prompt

    def _generate_response(self, prompt: str) -> str:
        """è°ƒç”¨ GLM-4 ç”Ÿæˆå›å¤"""
        response = self.glm_client.client.chat.completions.create(
            model=self.glm_client.model,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€è´´å¿ƒçš„é™ªä¼´å‹ AI åŠ©æ‰‹ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.8,  # ç¨é«˜çš„æ¸©åº¦ï¼Œå¢åŠ å¯¹è¯å¤šæ ·æ€§
        )

        return response.choices[0].message.content.strip()

    def get_session_memories(
        self, user_id: str, session_id: str
    ) -> List[MemoryFragment]:
        """è·å–ä¼šè¯çš„æ‰€æœ‰è®°å¿†ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        count = self.memory_storage.get_memory_count(user_id, session_id)
        print(f"ğŸ“Š ä¼šè¯ {session_id} å…±æœ‰ {count} æ¡è®°å¿†")

        # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºè¿”å›æ‰€æœ‰è®°å¿†
        return []

    def _is_likely_assistant_response(self, content: str) -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦å¯èƒ½æ˜¯ AI çš„å›å¤

        Args:
            content: å¾…åˆ¤æ–­çš„å†…å®¹

        Returns:
            True å¦‚æœå¯èƒ½æ˜¯ AI å›å¤
        """
        # AI å¸¸ç”¨è¯­æ¨¡å¼
        ai_patterns = [
            "å¸Œæœ›æˆ‘ä»¬èƒ½å¤Ÿ",
            "å¦‚æœä½ æ„¿æ„",
            "å¯ä»¥å’Œæˆ‘åˆ†äº«",
            "å¾ˆä¹æ„",
            "æˆ‘å¾ˆé«˜å…´",
            "å¾ˆé«˜å…´è®¤è¯†ä½ ",
            "è®©æˆ‘ä»¬ä¸€èµ·",
            "æ— è®ºæ˜¯ä»€ä¹ˆ",
            "æˆ‘éƒ½åœ¨è¿™é‡Œ",
            "å¸Œæœ›ä½ ",
            "ç¥æ„¿ä½ ",
            "ä½ çš„ä¸–ç•Œ",
            "ä½œä¸ºä¸€å",
        ]

        content_lower = content.lower()
        for pattern in ai_patterns:
            if pattern in content_lower:
                return True

        return False

    def _is_first_person_statement(self, content: str) -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦æ˜¯ç¬¬ä¸€äººç§°é™ˆè¿°ï¼ˆç”¨æˆ·è¯´çš„è¯ï¼‰

        Args:
            content: å¾…åˆ¤æ–­çš„å†…å®¹

        Returns:
            True å¦‚æœæ˜¯ç¬¬ä¸€äººç§°é™ˆè¿°
        """
        # ç¬¬ä¸€äººç§°æ ‡è®°
        first_person_indicators = [
            "æˆ‘å–œæ¬¢",
            "æˆ‘çˆ±",
            "æˆ‘è®¨åŒ",
            "æˆ‘æœ€",
            "æˆ‘æ˜¯",
            "æˆ‘æœ‰",
            "æˆ‘æƒ³",
            "æˆ‘è§‰å¾—",
            "æˆ‘æ„Ÿè§‰",
            "æˆ‘å®³æ€•",
            "æˆ‘æ‹…å¿ƒ",
            "æˆ‘ä»å°",
            "æˆ‘ç‰¹åˆ«",
            "æˆ‘å«",
            "æˆ‘çš„å·¥ä½œ",
            "æˆ‘çš„æ¢¦æƒ³",
            "æˆ‘çš„èŒä¸š",
        ]

        for indicator in first_person_indicators:
            if indicator in content:
                return True

        return False

    def _is_question(self, content: str) -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦æ˜¯é—®é¢˜

        Args:
            content: å¾…åˆ¤æ–­çš„å†…å®¹

        Returns:
            True å¦‚æœæ˜¯é—®é¢˜
        """
        # é—®å¥æ ‡è®°
        question_indicators = [
            "å—",
            "å‘¢",
            "ï¼Ÿ",
            "?",
            "ä½ çŸ¥é“",
            "ä½ çŸ¥é“å—",
            "æ˜¯ä»€ä¹ˆ",
            "ä¸ºä»€ä¹ˆ",
            "æ€ä¹ˆ",
            "å¦‚ä½•",
            "å“ªä¸ª",
            "å“ªäº›",
            "å¤šå°‘",
            "æœ‰æ²¡æœ‰",
            "æ˜¯ä¸æ˜¯",
        ]

        for indicator in question_indicators:
            if indicator in content:
                return True

        return False

    def _is_identity_info(self, content: str) -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦æ˜¯èº«ä»½ä¿¡æ¯ï¼ˆå§“åã€èŒä¸šç­‰ï¼‰

        Args:
            content: å¾…åˆ¤æ–­çš„å†…å®¹

        Returns:
            True å¦‚æœæ˜¯èº«ä»½ä¿¡æ¯
        """
        # èº«ä»½ä¿¡æ¯æ ‡è®°
        identity_indicators = [
            "æˆ‘å«",
            "æˆ‘çš„åå­—",
            "æˆ‘æ˜¯",
            "æˆ‘çš„èŒä¸š",
            "æˆ‘çš„å·¥ä½œ",
            "æˆ‘æ˜¯ä¸€å",
            "æˆ‘åš",
            "æˆ‘ä»äº‹",
        ]

        for indicator in identity_indicators:
            if indicator in content:
                return True

        return False

    def _are_similar_fragments(self, content1: str, content2: str) -> bool:
        """
        åˆ¤æ–­ä¸¤ä¸ªè®°å¿†ç‰‡æ®µæ˜¯å¦ç›¸ä¼¼ï¼ˆç”¨äºå»é‡ï¼‰

        Args:
            content1: è®°å¿†1çš„å†…å®¹
            content2: è®°å¿†2çš„å†…å®¹

        Returns:
            True å¦‚æœç›¸ä¼¼åº¦è¶…è¿‡é˜ˆå€¼
        """
        # ç®€å•æ–¹æ³•ï¼šå®Œå…¨åŒ¹é…
        if content1 == content2:
            return True

        # æ›´å¤æ‚çš„æ–¹æ³•ï¼šè®¡ç®—ç¼–è¾‘è·ç¦»æˆ–ä½™å¼¦ç›¸ä¼¼åº¦
        # è¿™é‡Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²åŒ…å«å…³ç³»
        if len(content1) > 0 and len(content2) > 0:
            # å¦‚æœä¸€ä¸ªåŒ…å«å¦ä¸€ä¸ªçš„æ ¸å¿ƒå†…å®¹ï¼ˆé•¿åº¦è¶…è¿‡80%ï¼‰
            if content1 in content2 and len(content1) > len(content2) * 0.8:
                return True
            if content2 in content1 and len(content2) > len(content1) * 0.8:
                return True

        return False

    def _boost_assistant_score(self, content: str) -> int:
        """
        æ ¹æ®å…³é”®è¯æå‡ AI å›å¤çš„é‡è¦æ€§åˆ†æ•°

        Args:
            content: AI çš„å›å¤å†…å®¹

        Returns:
            æå‡åçš„åˆ†æ•°ï¼ˆ3-10ï¼‰
        """
        boost_score = 3  # é»˜è®¤åˆ†æ•°

        # æ‰¿è¯ºç±»å…³é”®è¯ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        commitment_keywords = [
            "æˆ‘ä¼šä¸€ç›´", "æˆ‘ä¿è¯", "æ— è®ºå¦‚ä½•", "æ°¸è¿œ",
            "ä¸€å®š", "æ‰¿è¯º", "çº¦å®š", "ä¸‹æ¬¡ä¸€èµ·",
        ]
        if any(keyword in content for keyword in commitment_keywords):
            boost_score = max(boost_score, 7)

        # å»ºè®®ç±»å…³é”®è¯ï¼ˆä¸­ç­‰ä¼˜å…ˆçº§ï¼‰
        advice_keywords = [
            "ä½ å¯ä»¥è¯•è¯•", "å»ºè®®", "æ¨è", "å¯ä»¥å°è¯•",
            "è¯•è¯•çœ‹", "å¯ä»¥è€ƒè™‘", "è§£å†³æ–¹æ¡ˆ",
        ]
        if any(keyword in content for keyword in advice_keywords):
            boost_score = max(boost_score, 5)

        # æƒ…æ„Ÿæ”¯æŒç±»å…³é”®è¯ï¼ˆé«˜ä¼˜å…ˆçº§ï¼‰
        emotional_support_keywords = [
            "ç†è§£ä½ çš„æ„Ÿå—", "ä¸æ˜¯ä¸€ä¸ªäºº", "æˆ‘ä¸€ç›´åœ¨",
            "æ”¯æŒä½ ", "é™ªä¼´ä½ ", "ç›¸ä¿¡ä½ ", "ä½ èƒ½åšåˆ°",
            "åˆ«æ‹…å¿ƒ", "æ²¡äº‹çš„", "åŠ æ²¹",
        ]
        if any(keyword in content for keyword in emotional_support_keywords):
            boost_score = max(boost_score, 6)

        # æ·±åº¦æƒ…æ„Ÿè¡¨è¾¾ï¼ˆæœ€é«˜ä¼˜å…ˆçº§ï¼‰
        deep_emotional_keywords = [
            "æˆ‘çœŸçš„å¾ˆç†è§£", "æˆ‘å®Œå…¨ç†è§£", "æˆ‘æ˜ç™½",
            "æˆ‘å¾ˆå…³å¿ƒ", "æˆ‘å…³å¿ƒ", "æˆ‘ä¸ºä½ ",
        ]
        if any(keyword in content for keyword in deep_emotional_keywords):
            boost_score = max(boost_score, 8)

        return boost_score

    def _is_user_referencing_assistant(self, content: str) -> bool:
        """
        åˆ¤æ–­ç”¨æˆ·æ˜¯å¦åœ¨å¼•ç”¨ AI ä¹‹å‰è¯´è¿‡çš„è¯

        Args:
            content: ç”¨æˆ·è¯´çš„è¯

        Returns:
            True å¦‚æœç”¨æˆ·åœ¨å¼•ç”¨ AI çš„è¯
        """
        # å¼•ç”¨æ ‡è®°
        reference_patterns = [
            "ä½ è¯´è¿‡",
            "ä½ ä¹‹å‰è¯´è¿‡",
            "ä½ åˆšæ‰è¯´",
            "ä½ ä¹‹å‰è¯´",
            "ä½ åˆšæ‰",
            "ä½ ä¹‹å‰æåˆ°",
            "å°±åƒä½ è¯´çš„",
            "æ­£å¦‚ä½ è¯´",
            "è®°å¾—ä½ è¯´è¿‡",
            "ä½ è¯´è¿‡çš„è¯",
        ]

        content_lower = content.lower()
        for pattern in reference_patterns:
            if pattern in content_lower:
                return True

        return False
