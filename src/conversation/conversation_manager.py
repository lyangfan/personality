"""å¯¹è¯ç®¡ç†å™¨ - æ ¸å¿ƒç¼–æ’å™¨."""

from datetime import datetime
from typing import List, Optional, Tuple

from src.models import MemoryFragment
from src.retrieval.memory_retriever import MemoryRetriever, RetrievalConfig
from src.storage.memory_storage import MemoryStorage
from src.storage.session_manager import SessionManager
from src.storage.user_manager import UserManager
from src.utils.glm_client import GLMClient


class ConversationManager:
    """
    å¯¹è¯ç®¡ç†å™¨ - è®°å¿†å¢å¼ºçš„å¯¹è¯ç³»ç»Ÿ

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. ç®¡ç†å¯¹è¯çŠ¶æ€å’Œæ¶ˆæ¯å†å²
    2. å®æ—¶è®°å¿†æå–ï¼ˆå‘¨æœŸæ€§æˆ–è¾¾åˆ°é˜ˆå€¼ï¼‰
    3. è¯­ä¹‰æ£€ç´¢ç›¸å…³è®°å¿†
    4. å°†è®°å¿†æ³¨å…¥åˆ° Prompt
    5. ç”Ÿæˆä¸ªæ€§åŒ–å›å¤

    è®¾è®¡åŸåˆ™ï¼š
    - é™ªä¼´å‹ AI ä¼˜å…ˆï¼šæƒ…æ„Ÿè¿æ¥ã€ä¸ªæ€§åŒ–ã€å…³ç³»æ·±åº¦
    - ä¸Šä¸‹æ–‡èŠ‚çº¦ï¼šåªæ£€ç´¢å’Œæ³¨å…¥æœ€ç›¸å…³çš„è®°å¿†
    - å®æ—¶å“åº”ï¼šè®°å¿†æå–ä¸åº”é˜»å¡å¯¹è¯
    """

    def __init__(
        self,
        user_manager: UserManager,
        session_manager: SessionManager,
        memory_storage: MemoryStorage,
        glm_client: GLMClient,
        retrieval_config: Optional[RetrievalConfig] = None,
        memory_extract_threshold: int = 5,  # æ¯Nè½®æ¶ˆæ¯æå–ä¸€æ¬¡è®°å¿†
        max_context_memories: int = 5,  # æ³¨å…¥åˆ°ä¸Šä¸‹æ–‡çš„æœ€å¤§è®°å¿†æ•°
    ):
        """
        åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨

        Args:
            user_manager: ç”¨æˆ·ç®¡ç†å™¨
            session_manager: ä¼šè¯ç®¡ç†å™¨
            memory_storage: è®°å¿†å­˜å‚¨
            glm_client: GLM-4 å®¢æˆ·ç«¯
            retrieval_config: æ£€ç´¢é…ç½®
            memory_extract_threshold: è®°å¿†æå–é˜ˆå€¼ï¼ˆè½®æ•°ï¼‰
            max_context_memories: æœ€å¤§ä¸Šä¸‹æ–‡è®°å¿†æ•°
        """
        self.user_manager = user_manager
        self.session_manager = session_manager
        self.memory_storage = memory_storage
        self.glm_client = glm_client
        self.retriever = MemoryRetriever(memory_storage, retrieval_config)
        self.memory_extract_threshold = memory_extract_threshold
        self.max_context_memories = max_context_memories

        # æ¶ˆæ¯ç¼“å†²åŒºï¼ˆä¸´æ—¶å­˜å‚¨å½“å‰ä¼šè¯çš„æ¶ˆæ¯ï¼‰
        self._message_buffers: dict = {}

    def chat(
        self,
        user_id: str,
        session_id: str,
        user_message: str,
        extract_now: bool = False,
    ) -> str:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯å¹¶ç”Ÿæˆå›å¤

        Args:
            user_id: ç”¨æˆ·ID
            session_id: ä¼šè¯ID
            user_message: ç”¨æˆ·æ¶ˆæ¯
            extract_now: æ˜¯å¦ç«‹å³æå–è®°å¿†ï¼ˆé»˜è®¤ Falseï¼Œè¾¾åˆ°é˜ˆå€¼æ—¶è‡ªåŠ¨æå–ï¼‰

        Returns:
            AI å›å¤
        """
        # 1. å­˜å‚¨ç”¨æˆ·æ¶ˆæ¯åˆ°ç¼“å†²åŒº
        self._add_message_to_buffer(session_id, "user", user_message)

        # 2. æ£€æŸ¥æ˜¯å¦éœ€è¦æå–è®°å¿†
        message_count = len(self._message_buffers.get(session_id, []))
        should_extract = extract_now or (
            message_count % self.memory_extract_threshold == 0
        )

        if should_extract:
            self._extract_and_store_memories(user_id, session_id)

        # 3. æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = self.retriever.retrieve(
            user_id=user_id,
            session_id=session_id,
            query=user_message,
            config=RetrievalConfig(
                top_k=self.max_context_memories, min_importance=6
            ),  # åªæ£€ç´¢é‡è¦è®°å¿†
        )

        # 4. æ„å»ºå¸¦è®°å¿†çš„ Prompt
        prompt = self._build_prompt_with_memories(
            user_message=user_message, memories=relevant_memories
        )

        # 5. è°ƒç”¨ GLM-4 ç”Ÿæˆå›å¤
        ai_response = self._generate_response(prompt)

        # 6. å­˜å‚¨åŠ©æ‰‹æ¶ˆæ¯åˆ°ç¼“å†²åŒº
        self._add_message_to_buffer(session_id, "assistant", ai_response)

        # 7. æ›´æ–°ä¼šè¯ç»Ÿè®¡
        self.session_manager.update_session(
            session_id, message_count=message_count + 2
        )

        return ai_response

    def _add_message_to_buffer(self, session_id: str, role: str, content: str):
        """æ·»åŠ æ¶ˆæ¯åˆ°ç¼“å†²åŒº"""
        if session_id not in self._message_buffers:
            self._message_buffers[session_id] = []

        self._message_buffers[session_id].append(
            {"role": role, "content": content, "timestamp": datetime.now().isoformat()}
        )

    def _extract_and_store_memories(self, user_id: str, session_id: str):
        """ä»æ¶ˆæ¯ç¼“å†²åŒºæå–è®°å¿†å¹¶å­˜å‚¨"""
        if session_id not in self._message_buffers:
            return

        messages = self._message_buffers[session_id]
        if not messages:
            return

        # 1. æ‹¼æ¥å¯¹è¯æ–‡æœ¬
        conversation = "\n".join(
            [f"{msg['role']}: {msg['content']}" for msg in messages]
        )

        # 2. è°ƒç”¨ GLM-4 æå–è®°å¿†
        try:
            fragments_data = self.glm_client.extract_memory_with_scoring(conversation)

            # 3. è½¬æ¢ä¸º MemoryFragment å¯¹è±¡
            fragments = []
            for frag_data in fragments_data:
                fragment = MemoryFragment(
                    content=frag_data["content"],
                    timestamp=datetime.now(),
                    type=frag_data["type"],
                    entities=[],  # å¯ä»¥åç»­è¡¥å……
                    topics=[],
                    sentiment=frag_data["sentiment"],
                    importance_score=frag_data["importance_score"],
                    confidence=0.8,
                    metadata={"reasoning": frag_data.get("reasoning", "")},
                )
                fragments.append(fragment)

            # 4. è¿‡æ»¤å¹¶å­˜å‚¨
            important_fragments = [f for f in fragments if f.importance_score >= 5]
            if important_fragments:
                memory_ids = self.memory_storage.store_memories(
                    user_id=user_id, session_id=session_id, fragments=important_fragments
                )
                print(f"âœ… å­˜å‚¨äº† {len(memory_ids)} æ¡è®°å¿†")

        except Exception as e:
            print(f"âš ï¸  è®°å¿†æå–å¤±è´¥: {e}")

    def _build_prompt_with_memories(
        self, user_message: str, memories: List[Tuple[MemoryFragment, float]]
    ) -> str:
        """
        æ„å»ºå¸¦è®°å¿†çš„ Prompt

        è®¾è®¡è¦ç‚¹ï¼š
        1. è®°å¿†ä¼˜å…ˆçº§ï¼šæŒ‰ç›¸å…³æ€§æ’åº
        2. è®°å¿†æ•°é‡æ§åˆ¶ï¼šé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿
        3. é™ªä¼´å‹ä¼˜åŒ–ï¼šå¼ºè°ƒæƒ…æ„Ÿè¿æ¥ã€ä¸ªæ€§åŒ–
        """

        # è®°å¿†éƒ¨åˆ†
        if memories:
            memory_blocks = []
            for fragment, score in memories:
                memory_blocks.append(
                    f"- {fragment.content} (é‡è¦æ€§: {fragment.importance_score}/10, "
                    f"ç±»å‹: {fragment.type}, æƒ…æ„Ÿ: {fragment.sentiment})"
                )

            memories_text = "\n".join(memory_blocks)
        else:
            memories_text = "ï¼ˆè¿™æ˜¯æˆ‘ä»¬çš„ç¬¬ä¸€æ¬¡å¯¹è¯ï¼Œè¿˜æ²¡æœ‰å…³äºä½ çš„è®°å¿†ï¼‰"

        # æ„å»ºå®Œæ•´çš„ Promptï¼ˆä¸­æ–‡å‹å¥½ã€é™ªä¼´å‹ä¼˜åŒ–ï¼‰
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€è´´å¿ƒçš„é™ªä¼´å‹ AI åŠ©æ‰‹ã€‚

## å…³äºç”¨æˆ·çš„é‡è¦è®°å¿†

è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹å…³äºç”¨æˆ·çš„é‡è¦è®°å¿†ï¼Œåœ¨å›å¤ä¸­ä½“ç°ä½ çš„ç†è§£ï¼š

{memories_text}

## å¯¹è¯åŸåˆ™

1. **æƒ…æ„Ÿè¿æ¥ä¼˜å…ˆ**ï¼šå…³æ³¨ç”¨æˆ·çš„æƒ…æ„ŸçŠ¶æ€ï¼Œç»™äºˆæ¸©æš–å’Œæ”¯æŒ
2. **ä¸ªæ€§åŒ–å›å¤**ï¼šæ ¹æ®è®°å¿†ä¸­çš„ä¿¡æ¯ï¼Œæä¾›ä¸ªæ€§åŒ–çš„å›åº”
3. **è‡ªç„¶å¯¹è¯**ï¼šåƒæœ‹å‹ä¸€æ ·è‡ªç„¶äº¤æµï¼Œä¸è¦åˆ»æ„æåŠè®°å¿†
4. **å°Šé‡è¾¹ç•Œ**ï¼šå¯¹äºæ•æ„Ÿè¯é¢˜ä¿æŒå°Šé‡å’Œè°¨æ…
5. **ä¸­æ–‡è¡¨è¾¾**ï¼šä½¿ç”¨è‡ªç„¶ã€æ¸©æš–çš„ä¸­æ–‡è¡¨è¾¾

## å½“å‰å¯¹è¯

ç”¨æˆ·è¯´ï¼š{user_message}

è¯·åŸºäºè®°å¿†å’Œå¯¹è¯åŸåˆ™ï¼Œç»™å‡ºæ¸©æš–ã€è´´å¿ƒçš„å›å¤ï¼š"""

        return prompt

    def _generate_response(self, prompt: str) -> str:
        """è°ƒç”¨ GLM-4 ç”Ÿæˆå›å¤"""
        response = self.glm_client.client.chat.completions.create(
            model=self.glm_client.model,
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªæ¸©æš–ã€è´´å¿ƒçš„é™ªä¼´å‹ AI åŠ©æ‰‹ã€‚",
                },
                {"role": "user", "content": prompt},
            ],
            temperature=0.8,  # ç¨é«˜çš„æ¸©åº¦ï¼Œå¢åŠ å¯¹è¯å¤šæ ·æ€§
        )

        return response.choices[0].message.content.strip()

    def get_session_memories(
        self, user_id: str, session_id: str
    ) -> List[MemoryFragment]:
        """è·å–ä¼šè¯çš„æ‰€æœ‰è®°å¿†ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
        count = self.memory_storage.get_memory_count(user_id, session_id)
        print(f"ğŸ“Š ä¼šè¯ {session_id} å…±æœ‰ {count} æ¡è®°å¿†")

        # è¿™é‡Œå¯ä»¥æ‰©å±•ä¸ºè¿”å›æ‰€æœ‰è®°å¿†
        return []
