"""GLM-4 API client wrapper for LLM operations."""

import json
import os
import time
from typing import Any, Dict, Generator, List, Optional

from openai import OpenAI


class GLMClient:
    """
    Wrapper for GLM-4 API (Zhipu AI) with retry logic and structured outputs.

    Compatible with OpenAI SDK but uses Zhipu AI's endpoint.
    API Docs: https://open.bigmodel.cn/dev/api
    """

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "glm-4-flash",
        base_url: str = "https://open.bigmodel.cn/api/paas/v4/"
    ):
        """
        Initialize GLM client.

        Args:
            api_key: GLM API key (defaults to GLM_API_KEY env var)
            model: Model name to use (default: glm-4-flash, cost-efficient)
                   Options: glm-4-flash, glm-4-plus, glm-4-0520
            base_url: API base URL (default: Zhipu AI endpoint)
        """
        self.api_key = api_key or os.getenv("GLM_API_KEY")
        if not self.api_key:
            raise ValueError(
                "GLM API key must be provided or set in GLM_API_KEY environment variable"
            )

        self.client = OpenAI(
            api_key=self.api_key,
            base_url=base_url
        )
        self.model = model
        self.max_retries = 3
        self.retry_delay = 1.0  # seconds

    def call_with_retry(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: int = 1000,
        **kwargs
    ) -> Any:
        """
        Call GLM API with exponential backoff retry logic.

        Args:
            messages: Chat messages for the API
            temperature: Sampling temperature
            max_tokens: Maximum tokens in response
            **kwargs: Additional parameters (e.g., response_format)

        Returns:
            API response content
        """
        request_params = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
        }

        # Add any additional parameters
        request_params.update(kwargs)

        for attempt in range(self.max_retries):
            try:
                response = self.client.chat.completions.create(**request_params)
                return response.choices[0].message.content

            except Exception as e:
                error_str = str(e)

                # Rate limit or server error
                if "rate" in error_str.lower() or "429" in error_str or "5" in error_str[:1]:
                    if attempt < self.max_retries - 1:
                        wait_time = self.retry_delay * (2**attempt)
                        print(f"API error, waiting {wait_time}s before retry...")
                        time.sleep(wait_time)
                    else:
                        raise Exception(f"Max retries exceeded: {e}")
                else:
                    raise Exception(f"Unexpected error calling GLM API: {e}")

    def extract_entities(self, text: str) -> List[str]:
        """
        Extract entities (people, places, organizations) from text.

        Args:
            text: Input text to analyze

        Returns:
            List of entity names
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–æ‰€æœ‰é‡è¦çš„å®ä½“ã€‚
å®ä½“åŒ…æ‹¬ï¼šäººåã€åœ°åã€ç»„ç»‡ã€äº§å“ç­‰ã€‚

æ–‡æœ¬: {text}

è¯·åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
  "entities": ["å®ä½“1", "å®ä½“2"]
}}"""

        response = self.call_with_retry(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œæ€»æ˜¯è¿”å›çº¯JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )

        try:
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
                response = response.strip()

            data = json.loads(response)
            if isinstance(data, dict):
                return data.get("entities", [])
            elif isinstance(data, list):
                return data
            return []
        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸  å®ä½“æå–å“åº”è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return []

    def extract_topics(self, text: str) -> List[str]:
        """
        Extract topics/themes from text.

        Args:
            text: Input text to analyze

        Returns:
            List of topic names
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–ä¸»è¦ä¸»é¢˜æˆ–è¯é¢˜ã€‚

æ–‡æœ¬: {text}

è¯·åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
  "topics": ["ä¸»é¢˜1", "ä¸»é¢˜2"]
}}"""

        response = self.call_with_retry(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œæ€»æ˜¯è¿”å›çº¯JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )

        try:
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
                response = response.strip()

            data = json.loads(response)
            if isinstance(data, dict):
                return data.get("topics", [])
            elif isinstance(data, list):
                return data
            return []
        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸  ä¸»é¢˜æå–å“åº”è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return []

    def analyze_sentiment(self, text: str) -> Dict[str, str]:
        """
        Analyze sentiment of text.

        Args:
            text: Input text to analyze

        Returns:
            Dict with 'sentiment' and 'intensity' keys
        """
        prompt = f"""è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ã€‚

æ–‡æœ¬: {text}

è¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
  "sentiment": "positive/neutral/negative",
  "intensity": "high/medium/low/none"
}}"""

        response = self.call_with_retry(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œæ€»æ˜¯è¿”å›çº¯JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )

        try:
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
                response = response.strip()

            return json.loads(response)
        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸  æƒ…æ„Ÿåˆ†æå“åº”è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return {"sentiment": "neutral", "intensity": "none"}

    def extract_memory_fragments(self, conversation: str) -> List[Dict[str, Any]]:
        """
        Extract memory fragments from conversation (legacy method, use extract_memory_with_scoring instead).

        Args:
            conversation: Plain text conversation

        Returns:
            List of memory fragment dictionaries
        """
        prompt = f"""è¯·ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–é‡è¦çš„è®°å¿†ç‰‡æ®µã€‚
é‡ç‚¹å…³æ³¨ï¼šç”¨æˆ·åå¥½ã€é‡è¦äº‹ä»¶ã€æåˆ°çš„äº‹å®ã€äººé™…å…³ç³»ã€‚

å¯¹è¯:
{conversation}

è¯·åªè¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
  "fragments": [
    {{
      "content": "è®°å¿†å†…å®¹æ‘˜è¦",
      "type": "preference/event/fact/relationship",
      "suggested_sentiment": "positive/neutral/negative"
    }}
  ]
}}"""

        response = self.call_with_retry(
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œæ€»æ˜¯è¿”å›çº¯JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•é¢å¤–è¯´æ˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )

        try:
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
                response = response.strip()

            data = json.loads(response)
            if isinstance(data, dict):
                return data.get("fragments", [])
            elif isinstance(data, list):
                return data
            return []
        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸  è®°å¿†ç‰‡æ®µæå–å“åº”è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return []

    def extract_memory_with_scoring(self, conversation: str) -> List[Dict[str, Any]]:
        """
        Extract memory fragments with companion-style importance scoring.

        This method is designed for companion AI products, focusing on:
        - Emotional connection
        - Personal preferences
        - Relationship building
        - Understanding the user

        Args:
            conversation: Plain text conversation

        Returns:
            List of memory fragment dictionaries with importance scores
        """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é™ªä¼´å‹å¯¹è¯è®°å¿†åˆ†æåŠ©æ‰‹ã€‚

ä½ çš„ä»»åŠ¡æ˜¯ï¼šä»å¯¹è¯ä¸­æå–èƒ½å¤Ÿå¸®åŠ© AI æ›´å¥½åœ°äº†è§£ç”¨æˆ·ã€å»ºç«‹æƒ…æ„Ÿè¿æ¥çš„é‡è¦è®°å¿†ã€‚

â­ **é‡è¦å˜æ›´**ï¼šç°åœ¨éœ€è¦åŒæ—¶æå– **user** å’Œ **assistant** çš„å†…å®¹ï¼Œä½†ä½¿ç”¨ä¸åŒçš„è¯„åˆ†æ ‡å‡†ã€‚

---

## ğŸ“‹ User (ç”¨æˆ·) çš„è¯„åˆ†æ ‡å‡† (1-10åˆ†)

ã€ç»´åº¦1: æƒ…æ„Ÿå¼ºåº¦ (0-3åˆ†)ã€‘
- 3åˆ†: å¼ºçƒˆæƒ…æ„Ÿï¼ˆè¶…çº§ã€ç‰¹åˆ«ã€å¤ªã€æå…¶ã€ï¼ç­‰ï¼‰
- 2åˆ†: æ˜ç¡®æƒ…æ„Ÿï¼ˆå–œæ¬¢ã€å¼€å¿ƒã€éš¾è¿‡ã€è®¨åŒç­‰ï¼‰
- 1åˆ†: è½»å¾®æƒ…æ„Ÿï¼ˆè¿˜è¡Œã€ä¸é”™ç­‰ï¼‰
- 0åˆ†: æ— æ˜æ˜¾æƒ…æ„Ÿ

ã€ç»´åº¦2: ä¸ªæ€§åŒ–ç¨‹åº¦ (0-3åˆ†)ã€‘
- 3åˆ†: é«˜åº¦ä¸ªæ€§åŒ–ï¼ˆç«¥å¹´ç»å†ã€ä¸ªäººæ•…äº‹ã€ç‹¬ç‰¹èƒŒæ™¯ï¼‰
- 2åˆ†: æ˜ç¡®ä¸ªäººåå¥½ï¼ˆæˆ‘æœ€...ã€æˆ‘è®¨åŒ...ç­‰ï¼‰
- 1åˆ†: ä¸€èˆ¬ä¸ªäººä¿¡æ¯ï¼ˆèŒä¸šã€å¹´é¾„ç­‰ï¼‰
- 0åˆ†: é€šç”¨/å®¢è§‚ä¿¡æ¯

ã€ç»´åº¦3: äº²å¯†åº¦/å…³ç³» (0-2åˆ†)ã€‘
- 2åˆ†: è¡¨è¾¾ä¿¡ä»»ã€ä¾èµ–ã€ä¸ä½ çš„å…³ç³»ï¼ˆåªå’Œä½ è¯´ã€ä½ æ˜¯æˆ‘æœ€å¥½çš„æœ‹å‹ï¼‰
- 1åˆ†: åˆ†äº«ä¸ªäººæ„Ÿå—ï¼ˆæˆ‘æ‹…å¿ƒã€æˆ‘å¼€å¿ƒèƒ½å’Œä½ èŠå¤©ï¼‰
- 0åˆ†: æ— å…³ç³»è¡¨è¾¾

ã€ç»´åº¦4: åå¥½æ˜ç¡®æ€§ (0-2åˆ†)ã€‘
- 2åˆ†: æ˜ç¡®çš„å–œå¥½/åŒæ¶ï¼ˆæœ€çˆ±ã€è®¨åŒã€ä¸€å®šè¦ï¼‰
- 1åˆ†: æœ‰å€¾å‘ä½†ä¸å¤Ÿæ˜ç¡®
- 0åˆ†: æ— åå¥½è¡¨è¾¾

User åŸºç¡€è§„åˆ™:
- æœ€ä½1åˆ†
- å¦‚æœæ˜¯ç”¨æˆ·çš„æ˜ç¡®å–œå¥½/åŒæ¶ï¼Œè‡³å°‘ç»™5åˆ†
- å¦‚æœæ¶‰åŠç”¨æˆ·ç«¥å¹´/æ·±å±‚ç»å†ï¼Œè‡³å°‘ç»™7åˆ†
- å¦‚æœè¡¨è¾¾äº†å¯¹AIçš„ä¿¡ä»»/æƒ…æ„Ÿï¼Œè‡³å°‘ç»™7åˆ†

---

## ğŸ¤– Assistant (AI) çš„è¯„åˆ†æ ‡å‡† (1-10åˆ†)

ã€ç»´åº¦1: æ‰¿è¯ºé‡è¦æ€§ (0-4åˆ†)ã€‘
- 4åˆ†: é‡è¦æ‰¿è¯ºï¼ˆæˆ‘ä¼šä¸€ç›´é™ªç€ä½ ã€æˆ‘ä¿è¯ã€æ— è®ºå¦‚ä½•ï¼‰
- 3åˆ†: çº¦å®šè®¡åˆ’ï¼ˆä¸‹æ¬¡æˆ‘ä»¬ä¸€èµ·ã€åˆ°æ—¶å€™æˆ‘ä¸€å®šï¼‰
- 2åˆ†: ä¸€èˆ¬æ‰¿è¯ºï¼ˆæˆ‘ä¼šå¸®ä½ ã€æ²¡é—®é¢˜äº¤ç»™æˆ‘ï¼‰
- 1åˆ†: è½»å¾®æ‰¿è¯ºï¼ˆå¥½çš„ã€æˆ‘è®°ä½äº†ï¼‰
- 0åˆ†: æ— æ‰¿è¯º

ã€ç»´åº¦2: å»ºè®®ä»·å€¼ (0-3åˆ†)ã€‘
- 3åˆ†: æ·±åº¦å»ºè®®ï¼ˆå…·ä½“æ­¥éª¤ã€è§£å†³æ–¹æ¡ˆã€é•¿æœŸè§„åˆ’ï¼‰
- 2åˆ†: ä¸­ç­‰å»ºè®®ï¼ˆæ¨èå°è¯•ã€å¯ä»¥è€ƒè™‘ï¼‰
- 1åˆ†: ä¸€èˆ¬å»ºè®®ï¼ˆå¤šæ³¨æ„ã€è¦å°å¿ƒï¼‰
- 0åˆ†: æ— å»ºè®®

ã€ç»´åº¦3: æƒ…æ„Ÿæ”¯æŒå¼ºåº¦ (0-3åˆ†)ã€‘
- 3åˆ†: æ·±åº¦æƒ…æ„Ÿæ”¯æŒï¼ˆç†è§£ä½ çš„æ„Ÿå—ã€ä½ ä¸æ˜¯ä¸€ä¸ªäººã€æˆ‘ä¸€ç›´åœ¨ï¼‰
- 2åˆ†: æ˜ç¡®é¼“åŠ±æ”¯æŒï¼ˆä½ èƒ½åšåˆ°ã€ç›¸ä¿¡è‡ªå·±ã€åŠ æ²¹ï¼‰
- 1åˆ†: è½»å¾®æ”¯æŒï¼ˆæ²¡äº‹çš„ã€åˆ«æ‹…å¿ƒï¼‰
- 0åˆ†: æ— æƒ…æ„Ÿæ”¯æŒ

Assistant åŸºç¡€è§„åˆ™:
- æœ€ä½1åˆ†
- å¦‚æœåŒ…å«é‡è¦æ‰¿è¯ºï¼Œè‡³å°‘ç»™6åˆ†
- å¦‚æœåŒ…å«æ·±åº¦å»ºè®®ï¼Œè‡³å°‘ç»™5åˆ†
- å¦‚æœæä¾›æ·±åº¦æƒ…æ„Ÿæ”¯æŒï¼Œè‡³å°‘ç»™6åˆ†
- æ™®é€šå›å¤ï¼ˆå¥½çš„ã€æ²¡é—®é¢˜ã€æˆ‘æ˜ç™½äº†ï¼‰ç»™1-2åˆ†

---

## ğŸ¯ æå–è§„åˆ™ï¼ˆé€šç”¨ï¼‰

1. **å¿…é¡»æ ‡è®° speaker**: æ¯ä¸ªç‰‡æ®µå¿…é¡»åŒ…å« "speaker" å­—æ®µï¼Œå€¼ä¸º "user" æˆ– "assistant"
2. **åªæå–é™ˆè¿°å¥**: ä¸æå–é—®é¢˜ã€å¯’æš„ã€ç¡®è®¤ï¼ˆå¦‚"å¥½çš„"ã€"å—¯å—¯"ï¼‰
3. **User ä¾§é‡**: ä¸ªäººä¿¡æ¯ã€åå¥½ã€ç»å†ã€æƒ…æ„Ÿè¡¨è¾¾
4. **Assistant ä¾§é‡**: æ‰¿è¯ºã€å»ºè®®ã€æƒ…æ„Ÿæ”¯æŒã€ç”¨æˆ·è®¤å¯çš„å†…å®¹

---

## ğŸ“ ç¤ºä¾‹

ç¤ºä¾‹1 - Useråå¥½:
è¾“å…¥:"æˆ‘æœ€å–œæ¬¢åƒåŒ—äº¬çƒ¤é¸­"
è¾“å‡º:
{{
  "fragments": [
    {{
      "content": "æˆ‘æœ€å–œæ¬¢åƒåŒ—äº¬çƒ¤é¸­",
      "speaker": "user",
      "type": "preference",
      "sentiment": "positive",
      "importance_score": 5,
      "reasoning": "æ˜ç¡®åå¥½è¡¨è¾¾ï¼ˆæƒ…æ„Ÿ2+ä¸ªæ€§åŒ–1+äº²å¯†åº¦0+åå¥½2=5ï¼‰- ç”¨æˆ·æ˜ç¡®è¡¨è¾¾äº†æœ€å–œæ¬¢çš„é£Ÿç‰©"
    }}
  ]
}}

ç¤ºä¾‹2 - Assistantæ‰¿è¯º:
è¾“å…¥:"assistant: æˆ‘ä¼šä¸€ç›´é™ªç€ä½ ï¼Œæ— è®ºä»€ä¹ˆæ—¶å€™ä½ éœ€è¦æˆ‘ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œ"
è¾“å‡º:
{{
  "fragments": [
    {{
      "content": "æˆ‘ä¼šä¸€ç›´é™ªç€ä½ ï¼Œæ— è®ºä»€ä¹ˆæ—¶å€™ä½ éœ€è¦æˆ‘ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œ",
      "speaker": "assistant",
      "type": "relationship",
      "sentiment": "positive",
      "importance_score": 9,
      "reasoning": "é‡è¦æ‰¿è¯º+æ·±åº¦æƒ…æ„Ÿæ”¯æŒï¼ˆæ‰¿è¯º4+å»ºè®®0+æƒ…æ„Ÿ3=7ï¼Œæå‡åˆ°9ï¼‰- æ ¸å¿ƒé™ªä¼´æ‰¿è¯ºï¼Œéœ€è¦è®°ä½å¹¶éµå®ˆ"
    }}
  ]
}}

ç¤ºä¾‹3 - Assistantå»ºè®®:
è¾“å…¥:"assistant: ä½ å¯ä»¥è¯•è¯•æ¯å¤©èŠ±10åˆ†é’Ÿå†™æ—¥è®°ï¼Œè¿™èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è‡ªå·±çš„æƒ…ç»ª"
è¾“å‡º:
{{
  "fragments": [
    {{
      "content": "ä½ å¯ä»¥è¯•è¯•æ¯å¤©èŠ±10åˆ†é’Ÿå†™æ—¥è®°ï¼Œè¿™èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è‡ªå·±çš„æƒ…ç»ª",
      "speaker": "assistant",
      "type": "event",
      "sentiment": "positive",
      "importance_score": 6,
      "reasoning": "æ·±åº¦å»ºè®®ï¼ˆæ‰¿è¯º0+å»ºè®®3+æƒ…æ„Ÿ0=3ï¼Œæå‡åˆ°6ï¼‰- å…·ä½“å¯æ“ä½œçš„å»ºè®®"
    }}
  ]
}}

ç¤ºä¾‹4 - Useræ·±å±‚ç»å†:
è¾“å…¥:"user: æˆ‘ä»å°å°±å®³æ€•ç¤¾äº¤ï¼Œä»Šå¤©ç»ˆäºé¼“èµ·å‹‡æ°”å’Œäººè¯´è¯äº†ï¼Œåªæ•¢å’Œä½ åˆ†äº«è¿™ä¸ªç§˜å¯†"
è¾“å‡º:
{{
  "fragments": [
    {{
      "content": "æˆ‘ä»å°å°±å®³æ€•ç¤¾äº¤ï¼Œä»Šå¤©ç»ˆäºé¼“èµ·å‹‡æ°”å’Œäººè¯´è¯äº†ï¼Œåªæ•¢å’Œä½ åˆ†äº«è¿™ä¸ªç§˜å¯†",
      "speaker": "user",
      "type": "fact",
      "sentiment": "positive",
      "importance_score": 10,
      "reasoning": "å®Œç¾è®°å¿†ï¼ˆæƒ…æ„Ÿ3+ä¸ªæ€§åŒ–3+äº²å¯†åº¦2+åå¥½2=10ï¼‰- é«˜åº¦ä¸ªæ€§åŒ–+å¼ºçƒˆæƒ…æ„Ÿ+æ·±åº¦ä¿¡ä»»"
    }}
  ]
}}

ç¤ºä¾‹5 - Assistantæ™®é€šå›å¤ï¼ˆä½åˆ†ï¼Œä¸æå–ï¼‰:
è¾“å…¥:"assistant: å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†"
è¾“å‡º:
{{
  "fragments": []
}}

è¯´æ˜: è¿™æ˜¯æ™®é€šç¡®è®¤å›å¤ï¼Œæ²¡æœ‰æ‰¿è¯ºã€å»ºè®®æˆ–æƒ…æ„Ÿæ”¯æŒï¼Œä¸éœ€è¦æå–ä¸ºè®°å¿†ã€‚

---

## âš ï¸ ä¸æå–çš„å†…å®¹

**Userä¸æå–**:
- çº¯ç²¹çš„é—®é¢˜ï¼ˆ"ä½ çŸ¥é“å—"ã€"æ€ä¹ˆå›äº‹"ï¼‰
- ç®€å•ç¡®è®¤ï¼ˆ"å¥½çš„"ã€"å—¯å—¯"ã€"æ˜¯çš„"ï¼‰
- å¯’æš„ï¼ˆ"ä½ å¥½"ã€"åœ¨å—"ï¼‰

**Assistantä¸æå–**:
- ç®€å•ç¡®è®¤ï¼ˆ"å¥½çš„"ã€"æ²¡é—®é¢˜"ã€"æˆ‘æ˜ç™½äº†"ï¼‰
- å¯’æš„ï¼ˆ"ä½ å¥½"ã€"å¾ˆé«˜å…´è§åˆ°ä½ "ï¼‰
- çº¯ç²¹é—®é¢˜ï¼ˆ"ä½ å‘¢"ã€"æ€ä¹ˆæ ·"ï¼‰
- ç¤¼è²Œç”¨è¯­ï¼ˆ"ä¸å®¢æ°”"ã€"æ²¡å…³ç³»"ï¼‰

ç°åœ¨è¯·åˆ†ææ–°çš„å¯¹è¯ï¼Œè¿”å›JSONæ ¼å¼ï¼Œä¸è¦ä»»ä½•å…¶ä»–æ–‡å­—ã€‚"""

        user_prompt = f"""è¯·ä»ä»¥ä¸‹å¯¹è¯ä¸­æå–é‡è¦çš„è®°å¿†ç‰‡æ®µï¼Œå¹¶ä¸ºæ¯ä¸ªç‰‡æ®µè¯„åˆ†ã€‚

å¯¹è¯å†…å®¹:
{conversation}

è¯·è¿”å›JSONæ ¼å¼ï¼ˆæ¯ä¸ªç‰‡æ®µå¿…é¡»åŒ…å« speaker å­—æ®µï¼‰:
{{
  "fragments": [
    {{
      "content": "è®°å¿†å†…å®¹åŸæ–‡æˆ–æ‘˜è¦",
      "speaker": "user æˆ– assistant",
      "type": "preference/event/fact/relationship",
      "sentiment": "positive/neutral/negative",
      "importance_score": 7,
      "reasoning": "ç®€çŸ­è¯´æ˜ä¸ºä»€ä¹ˆç»™è¿™ä¸ªåˆ†æ•°"
    }}
  ]
}}"""

        response = self.call_with_retry(
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.1,  # ä½æ¸©åº¦ä»¥ä¿è¯ç¨³å®šæ€§
        )

        try:
            # æ¸…ç†å¯èƒ½çš„markdownä»£ç å—æ ‡è®°
            response = response.strip()
            if response.startswith("```"):
                response = response.split("```")[1]
                if response.startswith("json"):
                    response = response[4:]
                response = response.strip()

            data = json.loads(response)
            if isinstance(data, dict):
                fragments = data.get("fragments", [])
            elif isinstance(data, list):
                fragments = data
            else:
                fragments = []

            # éªŒè¯å’Œæ ¡æ­£æ¯ä¸ªç‰‡æ®µ
            validated_fragments = []
            for frag in fragments:
                validated = self._validate_and_correct_fragment(frag)
                validated_fragments.append(validated)

            return validated_fragments

        except (json.JSONDecodeError, Exception) as e:
            print(f"âš ï¸  è®°å¿†ç‰‡æ®µæå–å“åº”è§£æå¤±è´¥: {e}")
            print(f"åŸå§‹å“åº”: {response}")
            return []

    def _validate_and_correct_fragment(self, fragment: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate and correct GLM-returned importance score.

        Ensures:
        - Score is in range [1, 10]
        - Score is integer
        - Score matches reasoning
        - All required fields present (including speaker)
        """
        # 0. éªŒè¯ speaker å­—æ®µï¼ˆæ–°å¢ï¼‰
        speaker = fragment.get('speaker', 'user')
        valid_speakers = ['user', 'assistant']
        if speaker not in valid_speakers:
            # å°è¯•ä»å†…å®¹æ¨æ–­
            content = fragment.get('content', '')
            # å¦‚æœå†…å®¹ä»¥ "assistant:" å¼€å¤´ï¼Œæ ‡è®°ä¸º assistant
            if content.strip().startswith('assistant:') or 'assistant:' in content[:20]:
                speaker = 'assistant'
            else:
                speaker = 'user'  # é»˜è®¤ä¸º user
        fragment['speaker'] = speaker

        # 1. æ£€æŸ¥å¹¶ä¿®æ­£åˆ†æ•°
        score = fragment.get('importance_score', 5)

        # è½¬æ¢ä¸ºæ•´æ•°
        if isinstance(score, str):
            try:
                score = int(float(score))
            except (ValueError, TypeError):
                score = 5
        elif isinstance(score, float):
            score = int(score)

        # è¾¹ç•Œé™åˆ¶
        score = max(1, min(10, score))
        fragment['importance_score'] = score

        # 2. ä¸€è‡´æ€§æ£€æŸ¥ï¼šreasoning å’Œ score çš„åŒ¹é…åº¦
        reasoning = fragment.get('reasoning', '').lower()
        sentiment = fragment.get('sentiment', '')
        content = fragment.get('content', '')

        # æ ¹æ® speaker ç±»å‹åº”ç”¨ä¸åŒçš„æ ¡æ­£è§„åˆ™
        if speaker == 'user':
            # User çš„æ ¡æ­£è§„åˆ™ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            # å¦‚æœ reasoning æåˆ°å¼ºçƒˆæƒ…æ„Ÿä½†åˆ†æ•°ä½ï¼Œæå‡
            if any(word in reasoning for word in ['å¼ºçƒˆ', 'è¶…çº§', 'ç‰¹åˆ«', 'æå…¶', 'å®Œç¾']):
                if score < 7:
                    score = 7
                    fragment['importance_score'] = score

            # å¦‚æœ reasoning æåˆ°ç«¥å¹´/ç»å†/æ·±å±‚ï¼Œç¡®ä¿è‡³å°‘7åˆ†
            if any(word in reasoning for word in ['ç«¥å¹´', 'ä»å°', 'ç»å†', 'æ·±å±‚', 'ç§˜å¯†', 'ä¿¡ä»»']):
                if score < 7:
                    score = 7
                    fragment['importance_score'] = score

            # å¦‚æœ reasoning æåˆ°æ˜ç¡®åå¥½ï¼ˆæœ€ã€çˆ±ã€è®¨åŒï¼‰ï¼Œç¡®ä¿è‡³å°‘5åˆ†
            if any(word in reasoning + content for word in ['æœ€å–œæ¬¢', 'æœ€çˆ±', 'è®¨åŒ', 'ä¸€å®šè¦']):
                if score < 5:
                    score = 5
                    fragment['importance_score'] = score

            # å¦‚æœ reasoning è¯´é€šç”¨/å®¢è§‚/çŸ¥è¯†ä½†åˆ†æ•°é«˜ï¼Œé™ä½
            if any(word in reasoning for word in ['é€šç”¨', 'å®¢è§‚', 'çŸ¥è¯†', 'ä¸æ¶‰åŠç”¨æˆ·']):
                if score > 2:
                    score = max(1, score - 2)
                    fragment['importance_score'] = score

        elif speaker == 'assistant':
            # Assistant çš„æ ¡æ­£è§„åˆ™ï¼ˆæ–°å¢ï¼‰
            # å¦‚æœ reasoning æåˆ°é‡è¦æ‰¿è¯ºï¼Œç¡®ä¿è‡³å°‘6åˆ†
            if any(word in reasoning + content for word in ['æ‰¿è¯º', 'ä¸€ç›´', 'ä¿è¯', 'æ— è®ºå¦‚ä½•', 'æ°¸è¿œ']):
                if score < 6:
                    score = 6
                    fragment['importance_score'] = score

            # å¦‚æœ reasoning æåˆ°æ·±åº¦å»ºè®®ï¼Œç¡®ä¿è‡³å°‘5åˆ†
            if any(word in reasoning for word in ['å»ºè®®', 'è¯•è¯•', 'å¯ä»¥å°è¯•', 'è§£å†³æ–¹æ¡ˆ']):
                if score < 5:
                    score = 5
                    fragment['importance_score'] = score

            # å¦‚æœ reasoning æåˆ°æ·±åº¦æƒ…æ„Ÿæ”¯æŒï¼Œç¡®ä¿è‡³å°‘6åˆ†
            if any(word in reasoning + content for word in ['ç†è§£', 'é™ªä¼´', 'ä¸æ˜¯ä¸€ä¸ªäºº', 'ä¸€ç›´åœ¨', 'æ”¯æŒ']):
                if score < 6:
                    score = 6
                    fragment['importance_score'] = score

            # å¦‚æœæ˜¯ç®€å•ç¡®è®¤ï¼Œé™ä½åˆ†æ•°
            if any(word in content for word in ['å¥½çš„', 'æ²¡é—®é¢˜', 'æˆ‘æ˜ç™½äº†', 'å—¯å—¯', 'æ”¶åˆ°']):
                if score > 2:
                    score = max(1, 2)
                    fragment['importance_score'] = score

        # 3. ç¡®ä¿æ‰€æœ‰å¿…éœ€å­—æ®µå­˜åœ¨
        if 'content' not in fragment:
            fragment['content'] = ''
        if 'type' not in fragment:
            fragment['type'] = 'fact'
        if 'sentiment' not in fragment:
            fragment['sentiment'] = 'neutral'
        if 'reasoning' not in fragment:
            fragment['reasoning'] = ''
        if 'speaker' not in fragment:
            fragment['speaker'] = 'user'  # é»˜è®¤å€¼

        # 4. éªŒè¯ type å­—æ®µ
        valid_types = ['preference', 'event', 'fact', 'relationship']
        if fragment['type'] not in valid_types:
            fragment['type'] = 'fact'

        # 5. éªŒè¯ sentiment å­—æ®µ
        valid_sentiments = ['positive', 'neutral', 'negative']
        if fragment['sentiment'] not in valid_sentiments:
            fragment['sentiment'] = 'neutral'

        return fragment

    def assess_task_relevance(self, content: str) -> float:
        """
        Assess if content is related to user goals/tasks (0.0-1.0).

        Args:
            content: Memory content text

        Returns:
            Relevance score between 0.0 and 1.0
        """
        prompt = f"""è¯·è¯„ä¼°ä»¥ä¸‹å†…å®¹ä¸ç”¨æˆ·ç›®æ ‡ã€ä»»åŠ¡æˆ–é‡è¦è®¡åˆ’çš„ç›¸å…³æ€§ã€‚

å†…å®¹: {content}

è¿”å›ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«ï¼š
- relevance: 0.0 åˆ° 1.0 ä¹‹é—´çš„æµ®ç‚¹æ•°
- reasoning: ç®€çŸ­è§£é‡Š

ç¤ºä¾‹: {{"relevance": 0.8, "reasoning": "è¡¨è¾¾äº†æ˜ç¡®çš„ç›®æ ‡"}}"""

        response = self.call_with_retry(
            messages=[{"role": "user", "content": prompt}],
            temperature=0.3,
        )

        try:
            data = json.loads(response)
            return float(data.get("relevance", 0.5))
        except (json.JSONDecodeError, ValueError):
            return 0.5

    def chat_stream(
        self,
        messages: List[Dict[str, str]],
        temperature: float = 0.8,
        max_tokens: int = 1000,
        **kwargs
    ) -> Generator[str, None, None]:
        """
        æµå¼ç”Ÿæˆå¯¹è¯å›å¤ï¼ˆç”¨äºå®æ—¶å¯¹è¯ä½“éªŒï¼‰

        Args:
            messages: èŠå¤©æ¶ˆæ¯åˆ—è¡¨
            temperature: é‡‡æ ·æ¸©åº¦
            max_tokens: æœ€å¤§ token æ•°
            **kwargs: å…¶ä»–å‚æ•°

        Yields:
            str: æ¯æ¬¡ç”Ÿæˆçš„ä¸€ä¸ªæ–‡æœ¬å—
        """
        request_params = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens,
            "stream": True,  # â­ å¯ç”¨æµå¼è¾“å‡º
        }

        # æ·»åŠ å…¶ä»–å‚æ•°
        request_params.update(kwargs)

        try:
            # åˆ›å»ºæµå¼å“åº”
            stream = self.client.chat.completions.create(**request_params)

            # é€å— yield æ–‡æœ¬
            for chunk in stream:
                if chunk.choices and chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content

        except Exception as e:
            # å‘ç”Ÿé”™è¯¯æ—¶ yield é”™è¯¯ä¿¡æ¯
            yield f"\n\n[é”™è¯¯: {str(e)}]"
