#!/usr/bin/env python3
"""
æµ‹è¯•è®°å¿†é©±åŠ¨å¯¹è¯ç³»ç»Ÿ - ç«¯åˆ°ç«¯éªŒè¯
"""

import os
import sys
from datetime import datetime

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from src.conversation.conversation_manager import ConversationManager
from src.models import MemoryFragment
from src.retrieval.memory_retriever import RetrievalConfig
from src.storage.memory_storage import MemoryStorage
from src.storage.session_manager import SessionManager
from src.storage.user_manager import UserManager
from src.utils.glm_client import GLMClient


def test_memory_system():
    """æµ‹è¯•è®°å¿†ç³»ç»Ÿçš„å®Œæ•´æµç¨‹"""

    print("=" * 70)
    print("ğŸ§ª æµ‹è¯•è®°å¿†é©±åŠ¨å¯¹è¯ç³»ç»Ÿ")
    print("=" * 70)

    # 1. åˆå§‹åŒ–ç»„ä»¶
    print("\n1ï¸âƒ£ åˆå§‹åŒ–ç»„ä»¶...")
    user_manager = UserManager()
    session_manager = SessionManager()

    # â­ ä½¿ç”¨æ™ºè°± embedding-3
    import os
    embedding_model = os.getenv("EMBEDDING_MODEL", "simple")
    print(f"   ğŸ“Š ä½¿ç”¨ Embedding æ¨¡å‹: {embedding_model}")

    memory_storage = MemoryStorage(embedding_model=embedding_model)
    glm_client = GLMClient(
        api_key=os.getenv(
            "GLM_API_KEY", "670e7d42d2c64acf9f25696e24f67227.0SN6Hp2hsMASeNeZ"
        ),
        model="glm-4-flash",
    )

    retrieval_config = RetrievalConfig(
        top_k=5, min_importance=6, boost_recent=True, boost_importance=True
    )

    conversation_manager = ConversationManager(
        user_manager=user_manager,
        session_manager=session_manager,
        memory_storage=memory_storage,
        glm_client=glm_client,
        retrieval_config=retrieval_config,
        memory_extract_threshold=3,
        max_context_memories=5,
    )
    print("   âœ… ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")

    # 2. åˆ›å»ºæµ‹è¯•ç”¨æˆ·å’Œä¼šè¯
    print("\n2ï¸âƒ£ åˆ›å»ºæµ‹è¯•ç”¨æˆ·å’Œä¼šè¯...")
    user = user_manager.create_user("æµ‹è¯•ç”¨æˆ·")
    session = session_manager.create_session(user_id=user.user_id, title="æµ‹è¯•ä¼šè¯")
    print(f"   âœ… ç”¨æˆ·: {user.username} (ID: {user.user_id})")
    print(f"   âœ… ä¼šè¯: {session.title} (ID: {session.session_id})")

    # 3. æ‰‹åŠ¨æ·»åŠ ä¸€äº›æµ‹è¯•è®°å¿†
    print("\n3ï¸âƒ£ æ·»åŠ æµ‹è¯•è®°å¿†...")
    test_memories = [
        MemoryFragment(
            content="ç”¨æˆ·æœ€å–œæ¬¢åƒåŒ—äº¬çƒ¤é¸­ï¼Œç‰¹åˆ«æ˜¯çš®è„†è‚‰å«©çš„é‚£ç§",
            timestamp=datetime.now(),
            type="preference",
            entities=["åŒ—äº¬çƒ¤é¸­"],
            topics=["ç¾é£Ÿ", "åå¥½"],
            sentiment="positive",
            importance_score=8,
            confidence=0.9,
        ),
        MemoryFragment(
            content="ç”¨æˆ·å°æ—¶å€™æ›¾ç»è¢«ç‹—å’¬è¿‡ï¼Œæ‰€ä»¥ç°åœ¨æ¯”è¾ƒæ€•ç‹—",
            timestamp=datetime.now(),
            type="fact",
            entities=["ç‹—"],
            topics=["ç«¥å¹´", "ææƒ§"],
            sentiment="negative",
            importance_score=7,
            confidence=0.85,
        ),
        MemoryFragment(
            content="ç”¨æˆ·çš„æ¢¦æƒ³æ˜¯æˆä¸ºä¸€åä¼˜ç§€çš„è½¯ä»¶å·¥ç¨‹å¸ˆ",
            timestamp=datetime.now(),
            type="preference",
            entities=["è½¯ä»¶å·¥ç¨‹å¸ˆ"],
            topics=["æ¢¦æƒ³", "èŒä¸š"],
            sentiment="positive",
            importance_score=9,
            confidence=0.95,
        ),
    ]

    memory_ids = memory_storage.store_memories(
        user_id=user.user_id, session_id=session.session_id, fragments=test_memories
    )
    print(f"   âœ… æˆåŠŸå­˜å‚¨ {len(memory_ids)} æ¡æµ‹è¯•è®°å¿†")

    # 4. æµ‹è¯•è¯­ä¹‰æ£€ç´¢
    print("\n4ï¸âƒ£ æµ‹è¯•è¯­ä¹‰æ£€ç´¢...")
    test_queries = [
        "ä½ å–œæ¬¢åƒä»€ä¹ˆï¼Ÿ",
        "ä½ å®³æ€•ä»€ä¹ˆåŠ¨ç‰©ï¼Ÿ",
        "ä½ çš„æ¢¦æƒ³æ˜¯ä»€ä¹ˆï¼Ÿ",
    ]

    for query in test_queries:
        print(f"\n   ğŸ” æŸ¥è¯¢: {query}")
        memories = conversation_manager.retriever.retrieve(
            user_id=user.user_id,
            session_id=session.session_id,
            query=query,
            config=RetrievalConfig(top_k=3, min_importance=5),
        )

        for fragment, score in memories:
            print(f"   ğŸ“ [{score:.2f}] {fragment.content}")
            print(f"      ç±»å‹: {fragment.type}, é‡è¦æ€§: {fragment.importance_score}/10")

    # 5. æµ‹è¯•è®°å¿†ç»Ÿè®¡
    print("\n5ï¸âƒ£ è®°å¿†ç»Ÿè®¡...")
    count = memory_storage.get_memory_count(user.user_id, session.session_id)
    print(f"   ğŸ“Š æ€»è®°å¿†æ•°: {count} æ¡")

    print("\n" + "=" * 70)
    print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿè¿è¡Œæ­£å¸¸")
    print("=" * 70)

    return user, session


def test_conversation_flow():
    """æµ‹è¯•å®Œæ•´å¯¹è¯æµç¨‹"""

    print("\n" + "=" * 70)
    print("ğŸ’¬ æµ‹è¯•å¯¹è¯æµç¨‹")
    print("=" * 70)

    # åˆå§‹åŒ–ç³»ç»Ÿ
    import os

    user_manager = UserManager()
    session_manager = SessionManager()

    # â­ ä½¿ç”¨æ™ºè°± embedding-3
    embedding_model = os.getenv("EMBEDDING_MODEL", "simple")
    print(f"   ğŸ“Š ä½¿ç”¨ Embedding æ¨¡å‹: {embedding_model}")

    memory_storage = MemoryStorage(embedding_model=embedding_model)
    glm_client = GLMClient(
        api_key=os.getenv(
            "GLM_API_KEY", "670e7d42d2c64acf9f25696e24f67227.0SN6Hp2hsMASeNeZ"
        ),
        model="glm-4-flash",
    )

    conversation_manager = ConversationManager(
        user_manager=user_manager,
        session_manager=session_manager,
        memory_storage=memory_storage,
        glm_client=glm_client,
        memory_extract_threshold=2,  # æ¯2è½®æå–ä¸€æ¬¡
        max_context_memories=5,
    )

    # åˆ›å»ºç”¨æˆ·å’Œä¼šè¯
    user = user_manager.create_user("å¯¹è¯æµ‹è¯•ç”¨æˆ·")
    session = session_manager.create_session(user_id=user.user_id, title="å¯¹è¯æµ‹è¯•")

    print(f"\nğŸ‘¤ ç”¨æˆ·: {user.username}")
    print(f"ğŸ’¬ ä¼šè¯: {session.title}\n")

    # æ¨¡æ‹Ÿå¯¹è¯
    test_conversations = [
        "æˆ‘æœ€å–œæ¬¢åƒçš„æ˜¯ç«é”…",
        "ç‰¹åˆ«æ˜¯éº»è¾£é”…åº•",
        "ä½ çŸ¥é“æˆ‘å–œæ¬¢åƒä»€ä¹ˆå—ï¼Ÿ",  # åº”è¯¥å¬å›ç«é”…çš„è®°å¿†
    ]

    for user_message in test_conversations:
        print(f"ğŸ‘¤ ç”¨æˆ·: {user_message}")
        print("ğŸ¤– AI: ", end="", flush=True)

        try:
            ai_response = conversation_manager.chat(
                user_id=user.user_id,
                session_id=session.session_id,
                user_message=user_message,
            )
            print(ai_response)
        except Exception as e:
            print(f"(é”™è¯¯: {e})")

        print()

    # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
    memory_count = memory_storage.get_memory_count(user.user_id, session.session_id)
    print(f"ğŸ“Š å¯¹è¯ç»“æŸï¼Œå…±æå– {memory_count} æ¡è®°å¿†")


if __name__ == "__main__":
    try:
        # æµ‹è¯•è®°å¿†ç³»ç»Ÿ
        test_memory_system()

        # æµ‹è¯•å¯¹è¯æµç¨‹ï¼ˆå¯é€‰ï¼Œéœ€è¦è°ƒç”¨ GLM APIï¼‰
        print("\n" + "=" * 70)
        print("æ˜¯å¦æµ‹è¯•å¯¹è¯æµç¨‹ï¼Ÿ(éœ€è¦è°ƒç”¨ GLM API)")
        choice = input("è¾“å…¥ y ç»§ç»­ï¼Œå…¶ä»–é”®è·³è¿‡: ").strip().lower()

        if choice == "y":
            test_conversation_flow()

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback

        traceback.print_exc()
