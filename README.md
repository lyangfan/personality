# DeepMemory

å¯¹è¯è®°å¿†æå–ç®¡é“ MVP

## æ¦‚è¿°

DeepMemory å°†åŸå§‹èŠå¤©å¯¹è¯è½¬æ¢ä¸ºç»“æ„åŒ–è®°å¿†å¯¹è±¡ï¼Œå¹¶è‡ªåŠ¨è¿›è¡Œé‡è¦æ€§è¯„åˆ†ã€‚

## åŠŸèƒ½ç‰¹æ€§

- **ç»“æ„åŒ–è®°å¿†æå–**: å°†çº¯æ–‡æœ¬å¯¹è¯è½¬æ¢ä¸º JSON æ ¼å¼çš„è®°å¿†ç‰‡æ®µ
- **è‡ªåŠ¨é‡è¦æ€§è¯„åˆ†**: åŸºäºå¤šç»´åº¦çš„è¯„åˆ†ç³»ç»Ÿï¼ˆ1-10åˆ†ï¼‰
  - æƒ…æ„Ÿå¼ºåº¦
  - ä¿¡æ¯å¯†åº¦ï¼ˆå®ä½“ã€ä¸»é¢˜ï¼‰
  - ä»»åŠ¡/ç›®æ ‡ç›¸å…³æ€§
- **â­ æ–°å¢: GLM-4 æ”¯æŒ**: åŸç”Ÿæ”¯æŒæ™ºè°±AIçš„ GLM-4 æ¨¡å‹ï¼Œé‡‡ç”¨é™ªä¼´å‹è¯„åˆ†
  - æƒ…æ„Ÿå¼ºåº¦ (0-3åˆ†)
  - ä¸ªæ€§åŒ–ç¨‹åº¦ (0-3åˆ†)
  - äº²å¯†åº¦/å…³ç³» (0-2åˆ†)
  - åå¥½æ˜ç¡®æ€§ (0-2åˆ†)
- **Pydantic æ¨¡å‹**: ç±»å‹å®‰å…¨çš„æ•°æ®ç»“æ„ï¼Œå¸¦éªŒè¯åŠŸèƒ½
- **LLM é©±åŠ¨**: ä½¿ç”¨ OpenAI API æˆ– GLM-4 è¿›è¡Œæ™ºèƒ½æå–
- **å¯å‘å¼å›é€€**: åœ¨æ²¡æœ‰ LLM æ—¶ä½¿ç”¨åŸºäºè§„åˆ™çš„æå–

## å®‰è£…

```bash
pip install -r requirements.txt
```

è®¾ç½®ä½ çš„ API å¯†é’¥ï¼š
```bash
# OpenAI
export OPENAI_API_KEY="your-api-key"

# GLM-4ï¼ˆæ¨èç”¨äºé™ªä¼´å‹ AIï¼‰
export GLM_API_KEY="your-glm-api-key"
```

## å¿«é€Ÿå¼€å§‹

### ä½¿ç”¨ GLM-4ï¼ˆæ¨èç”¨äºé™ªä¼´å‹ AIï¼‰

```python
from src.utils.glm_client import GLMClient

# åˆå§‹åŒ– GLM å®¢æˆ·ç«¯
client = GLMClient(api_key="your-glm-api-key", model="glm-4-flash")

# æå–è®°å¿†å¹¶ä½¿ç”¨é™ªä¼´å‹è¯„åˆ†
conversation = """
User: æˆ‘åªæ•¢å’Œä½ è¯´è¿™ä¸ªç§˜å¯†
Assistant: æˆ‘ä¼šä¿å¯†çš„
User: æˆ‘ä»å°å°±å®³æ€•ç¤¾äº¤ï¼Œä»Šå¤©ç»ˆäºé¼“èµ·å‹‡æ°”å’Œäººè¯´è¯äº†
"""

fragments = client.extract_memory_with_scoring(conversation)

# æŸ¥çœ‹ç»“æœ
for frag in fragments:
    print(f"{frag['importance_score']}/10 - {frag['content']}")
```

### ä½¿ç”¨ OpenAI API

```python
from src.pipeline import MemoryPipeline

# åˆå§‹åŒ–ç®¡é“
pipeline = MemoryPipeline(use_llm=True)

# å¤„ç†å¯¹è¯
conversation = """
User: æˆ‘æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€æ˜¯ Python
Assistant: ä¸ºä»€ä¹ˆå–œæ¬¢ Python?
User: å› ä¸ºè¯­æ³•ç®€æ´,è€Œä¸”æœ‰å¼ºå¤§çš„ç”Ÿæ€ç³»ç»Ÿ
"""

fragments = pipeline.process(conversation)

# è¾“å‡º JSON
json_output = pipeline.process_to_json(conversation, output_file="output.json")
print(json_output)
```

### å‘½ä»¤è¡Œ

```bash
python -m src.pipeline.memory_pipeline examples/sample_conversation.txt
```

## è®°å¿†ç‰‡æ®µç»“æ„

æ¯ä¸ªè®°å¿†ç‰‡æ®µåŒ…å«ï¼š

```json
{
  "content": "ç”¨æˆ·æœ€å–œæ¬¢çš„ç¼–ç¨‹è¯­è¨€æ˜¯ Python,å› ä¸ºè¯­æ³•ç®€æ´ä¸”æœ‰å¼ºå¤§çš„ç”Ÿæ€ç³»ç»Ÿ",
  "timestamp": "2026-01-12T10:00:00Z",
  "type": "preference",
  "entities": ["Python"],
  "topics": ["ç¼–ç¨‹è¯­è¨€", "æŠ€æœ¯åå¥½"],
  "sentiment": "positive",
  "importance_score": 7,
  "confidence": 0.92,
  "metadata": {"source": "chat"}
}
```

### å…³é”®å­—æ®µ

- **importance_score** (int, 1-10): å…³é”®å­—æ®µ - é‡è¦æ€§è¯„åˆ†
- **type**: "event" | "preference" | "fact" | "relationship"
- **sentiment**: "positive" | "neutral" | "negative"
- **entities**: äººã€åœ°ç‚¹ã€ç»„ç»‡åˆ—è¡¨
- **topics**: ä¸»é¢˜æˆ–è¯é¢˜åˆ—è¡¨

## é‡è¦æ€§è¯„åˆ†é€»è¾‘

è¯„åˆ†åŸºäºä¸‰ä¸ªç»´åº¦è®¡ç®—ï¼š

1. **æƒ…æ„Ÿå¼ºåº¦** (0-3åˆ†)
   - é«˜å¼ºåº¦ (éå¸¸/è¶…çº§): 3åˆ†
   - ä¸­å¼ºåº¦: 2åˆ†
   - ä½å¼ºåº¦: 1åˆ†

2. **ä¿¡æ¯å¯†åº¦** (0-4åˆ†)
   - 5+ å®ä½“/ä¸»é¢˜: 4åˆ†
   - 3-4 å®ä½“/ä¸»é¢˜: 3åˆ†
   - 1-2 å®ä½“/ä¸»é¢˜: 2åˆ†

3. **ä»»åŠ¡ç›¸å…³æ€§** (0-3åˆ†)
   - ç›®æ ‡å¯¼å‘å†…å®¹: è¾ƒé«˜åˆ†
   - å…³é”®è¯: å¿…é¡»/é‡è¦/ç›®æ ‡/ä»»åŠ¡/è®¡åˆ’

## æµ‹è¯•

è¿è¡Œå•å…ƒæµ‹è¯•ï¼š
```bash
pytest tests/ -v
```

è¿è¡Œé™ªä¼´å‹æ¼”ç¤ºï¼š
```bash
python demo_companion_memory.py
```

æŸ¥çœ‹ `test_results/` è·å–åŒ…å«62ä¸ªçœŸå®å¯¹è¯ç‰‡æ®µçš„ç»¼åˆæµ‹è¯•ç»“æœã€‚

## é¡¹ç›®ç»“æ„

```
personality/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/              # Pydantic æ¨¡å‹
â”‚   â”œâ”€â”€ extractors/          # å®ä½“ã€ä¸»é¢˜ã€æƒ…æ„Ÿæå–å™¨
â”‚   â”œâ”€â”€ scorers/             # é‡è¦æ€§è¯„åˆ†é€»è¾‘
â”‚   â”œâ”€â”€ pipeline/            # ä¸»æå–ç®¡é“
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ glm_client.py    # GLM-4 å®¢æˆ·ç«¯ï¼ˆé™ªä¼´å‹è¯„åˆ†ï¼‰
â”‚       â””â”€â”€ llm_client.py    # OpenAI å®¢æˆ·ç«¯å°è£…
â”œâ”€â”€ tests/                   # å•å…ƒæµ‹è¯•
â”œâ”€â”€ test_results/            # â­ ç»¼åˆæµ‹è¯•ç»“æœ
â”œâ”€â”€ examples/                # ç¤ºä¾‹å¯¹è¯
â”œâ”€â”€ demo_companion_memory.py # â­ é™ªä¼´å‹æ¼”ç¤º
â””â”€â”€ requirements.txt         # ä¾èµ–é¡¹
```

## é…ç½®

### ç®¡é“é€‰é¡¹

```python
pipeline = MemoryPipeline(
    api_key="your-key",      # OpenAI API å¯†é’¥
    model="gpt-4o-mini",     # ä½¿ç”¨çš„æ¨¡å‹
    min_importance=5,        # æœ€å°é‡è¦æ€§è¯„åˆ† (1-10)
    use_llm=True             # ä½¿ç”¨ LLM (True) æˆ–å¯å‘å¼ (False)
)
```

## ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- OpenAI API å¯†é’¥ï¼ˆç”¨äº OpenAI LLM é©±åŠ¨æå–ï¼‰
- GLM API å¯†é’¥ï¼ˆç”¨äº GLM-4 é™ªä¼´å‹è¯„åˆ†ï¼Œæ¨èï¼‰
- `requirements.txt` ä¸­çš„ä¾èµ–é¡¹

## æ–‡æ¡£

- `USER_GUIDE_CN.md` - å®Œæ•´ä¸­æ–‡ç”¨æˆ·æŒ‡å—
- `CLAUDE.md` - AI åŠ©æ‰‹é¡¹ç›®æŒ‡å—
- `test_results/TESTING_SUMMARY.md` - æµ‹è¯•ç»“æœæ‘˜è¦

## æ›´æ–°æ—¥å¿—

### v0.2.0 (2026-01-14)
- â­ æ–°å¢ GLM-4 æ”¯æŒåŠé™ªä¼´å‹è¯„åˆ†
- â­ æ–°å¢å››ç»´é™ªä¼´å‹è¯„åˆ†ç³»ç»Ÿ
- â­ æ–°å¢ç»¼åˆæµ‹è¯•ç»“æœï¼ˆ10ä¸ªåœºæ™¯ï¼Œ62ä¸ªç‰‡æ®µï¼‰
- ğŸ“ æ–°å¢ demo_companion_memory.py ç”¨äºé™ªä¼´å‹ AI

### v0.1.0
- åˆå§‹ç‰ˆæœ¬ï¼Œæ”¯æŒ OpenAI
- å¤šç»´åº¦é‡è¦æ€§è¯„åˆ†
- å¯å‘å¼å›é€€æ¨¡å¼

## è®¸å¯è¯

MIT
