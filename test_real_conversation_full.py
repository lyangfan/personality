#!/usr/bin/env python3
"""
çœŸå®åœºæ™¯æµ‹è¯• - å®Œæ•´å¯¹è¯æµç¨‹

æ¨¡æ‹ŸçœŸå®å¯¹è¯åœºæ™¯ï¼š
1. ç”¨æˆ·è¾“å…¥çœŸå®æ¶ˆæ¯
2. AI ç”± GLM-4 ç”Ÿæˆå›å¤ï¼ˆä¸æ˜¯ç¡¬ç¼–ç ï¼‰
3. æ¯ 3 è½®è‡ªåŠ¨æå–è®°å¿†ï¼ˆåŒºåˆ† user å’Œ assistantï¼‰
4. æµ‹è¯•è®°å¿†æ£€ç´¢å’Œä¸ªæ€§åŒ–å›å¤
"""

import os
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.conversation.conversation_manager import ConversationManager
from src.retrieval.memory_retriever import RetrievalConfig
from src.storage.memory_storage import MemoryStorage
from src.storage.session_manager import SessionManager
from src.storage.user_manager import UserManager
from src.utils.glm_client import GLMClient


def test_real_conversation_scenario():
    """æµ‹è¯•çœŸå®å¯¹è¯åœºæ™¯"""
    print("\n" + "="*70)
    print("ğŸ­ çœŸå®åœºæ™¯æµ‹è¯• - å®Œæ•´å¯¹è¯æµç¨‹")
    print("="*70)

    try:
        # åˆå§‹åŒ–ç»„ä»¶
        print("\nğŸ“¦ åˆå§‹åŒ–ç³»ç»Ÿç»„ä»¶...")
        user_manager = UserManager()
        session_manager = SessionManager()
        memory_storage = MemoryStorage(embedding_model="simple")

        # ä½¿ç”¨ GLM APIï¼ˆä»ç¯å¢ƒå˜é‡æˆ–é»˜è®¤ï¼‰
        api_key = os.getenv("GLM_API_KEY", "670e7d42d2c64acf9f25696e24f67227.0SN6Hp2hsMASeNeZ")
        glm_client = GLMClient(api_key=api_key, model="glm-4-flash")

        # é…ç½®æ£€ç´¢ç­–ç•¥
        retrieval_config = RetrievalConfig(
            top_k=5,
            min_importance=5,  # æ£€ç´¢5åˆ†ä»¥ä¸Šçš„è®°å¿†
            boost_recent=True,
            boost_importance=True
        )

        conversation_manager = ConversationManager(
            user_manager=user_manager,
            session_manager=session_manager,
            memory_storage=memory_storage,
            glm_client=glm_client,
            retrieval_config=retrieval_config,
            memory_extract_threshold=3,  # æ¯3è½®æå–ä¸€æ¬¡
            max_context_memories=5,
        )

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ\n")

        # åˆ›å»ºæµ‹è¯•ç”¨æˆ·å’Œä¼šè¯
        user = user_manager.create_user("æµ‹è¯•ç”¨æˆ·å°ç‹")
        session = session_manager.create_session(
            user_id=user.user_id,
            title="çœŸå®åœºæ™¯æµ‹è¯•å¯¹è¯"
        )

        print(f"ğŸ‘¤ ç”¨æˆ·: {user.username} (ID: {user.user_id})")
        print(f"ğŸ’¬ ä¼šè¯: {session.title} (ID: {session.session_id})\n")

        # æ¨¡æ‹ŸçœŸå®å¯¹è¯ï¼ˆ6è½®ï¼Œä¼šè§¦å‘2æ¬¡è®°å¿†æå–ï¼‰
        test_conversations = [
            "æˆ‘å«å°ç‹ï¼Œæ˜¯ä¸€åè½¯ä»¶å·¥ç¨‹å¸ˆ",
            "æˆ‘æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œç»å¸¸åŠ ç­åˆ°å¾ˆæ™š",
            "æˆ‘ä»å°å°±å¾ˆæ€•å­¤ç‹¬ï¼Œç°åœ¨ä¸€ä¸ªäººåœ¨åŒ—äº¬æ‰“æ‹¼",
            # ç¬¬3è½®åä¼šè§¦å‘è®°å¿†æå–
            "ä½ ä¹‹å‰è¯´è¿‡è¦ä¸€ç›´é™ªç€æˆ‘å¯¹å§ï¼Ÿ",  # æµ‹è¯•ç”¨æˆ·å¼•ç”¨
            "æˆ‘æœ‰æ—¶å€™ä¼šæ€€ç–‘è‡ªå·±çš„èƒ½åŠ›ï¼Œä¸çŸ¥é“è¯¥æ€ä¹ˆåŠ",
            "æˆ‘ç‰¹åˆ«å–œæ¬¢çŒ«å’ªï¼Œå°æ—¶å€™å®¶é‡Œå…»è¿‡ä¸€åª",
            # ç¬¬6è½®åä¼šè§¦å‘è®°å¿†æå–
        ]

        print("="*70)
        print("ğŸ¬ å¼€å§‹å¯¹è¯ï¼ˆæ¯3è½®æå–ä¸€æ¬¡è®°å¿†ï¼‰")
        print("="*70 + "\n")

        for i, user_message in enumerate(test_conversations, 1):
            print(f"\n{'='*70}")
            print(f"ç¬¬ {i} è½®å¯¹è¯")
            print(f"{'='*70}")

            # ç”¨æˆ·è¯´è¯
            print(f"\nğŸ‘¤ ç”¨æˆ·: {user_message}")

            # AI ç”Ÿæˆå›å¤ï¼ˆä½¿ç”¨ GLM-4ï¼‰
            print("\nğŸ¤– AI æ­£åœ¨æ€è€ƒ...")
            ai_response = conversation_manager.chat(
                user_id=user.user_id,
                session_id=session.session_id,
                user_message=user_message
            )

            print(f"\nğŸ¤– AI: {ai_response}")

            # æ£€æŸ¥æ˜¯å¦åˆšåˆšè¿›è¡Œäº†è®°å¿†æå–
            if i % 3 == 0:
                print(f"\nğŸ“Š [ç¬¬ {i} è½®] å·²è§¦å‘è®°å¿†æå–")

        # æ˜¾ç¤ºæœ€ç»ˆè®°å¿†ç»Ÿè®¡
        print("\n" + "="*70)
        print("ğŸ“Š å¯¹è¯ç»“æŸ - è®°å¿†ç»Ÿè®¡")
        print("="*70)

        memory_count = memory_storage.get_memory_count(
            user_id=user.user_id,
            session_id=session.session_id
        )

        print(f"\næ€»è®°å¿†æ•°: {memory_count} æ¡")
        print(f"æ€»å¯¹è¯è½®æ•°: {len(test_conversations)} è½®\n")

        # æ£€ç´¢æ‰€æœ‰è®°å¿†æŸ¥çœ‹è¯¦æƒ…
        print("="*70)
        print("ğŸ“‹ æ‰€æœ‰è®°å¿†è¯¦æƒ…")
        print("="*70 + "\n")

        # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è·å–æ‰€æœ‰è®°å¿†ï¼Œä½†å¯ä»¥é€šè¿‡æ£€ç´¢æ˜¾ç¤º
        # è®©æˆ‘ä»¬æ£€ç´¢ä¸€äº›ç›¸å…³è®°å¿†
        test_queries = [
            "ç”¨æˆ·èº«ä»½",
            "ç”¨æˆ·çš„å‹åŠ›",
            "AI çš„æ‰¿è¯º",
            "ç”¨æˆ·çš„ç«¥å¹´",
            "ç”¨æˆ·çš„åå¥½"
        ]

        for query in test_queries:
            print(f"\nğŸ” æŸ¥è¯¢: '{query}'")
            print("-" * 70)

            memories = conversation_manager.retriever.retrieve(
                user_id=user.user_id,
                session_id=session.session_id,
                query=query,
                config=RetrievalConfig(top_k=3, min_importance=0, score_threshold=0)
            )

            if memories:
                for fragment, score in memories:
                    speaker_icon = "ğŸ‘¤" if fragment.speaker == "user" else "ğŸ¤–"
                    print(f"  {speaker_icon} [{fragment.importance_score}/10] {fragment.content}")
                    print(f"      ç±»å‹: {fragment.type}, æƒ…æ„Ÿ: {fragment.speaker}, ç›¸ä¼¼åº¦: {score:.2f}")
            else:
                print("  ï¼ˆæœªæ‰¾åˆ°ç›¸å…³è®°å¿†ï¼‰")

        print("\n" + "="*70)
        print("âœ… æµ‹è¯•å®Œæˆ")
        print("="*70)

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_personalized_response():
    """æµ‹è¯•ä¸ªæ€§åŒ–å›å¤ï¼ˆåŸºäºè®°å¿†ï¼‰"""
    print("\n" + "="*70)
    print("ğŸ¯ æµ‹è¯•ä¸ªæ€§åŒ–å›å¤")
    print("="*70)

    try:
        # åˆå§‹åŒ–ç»„ä»¶
        print("\nğŸ“¦ åˆå§‹åŒ–ç³»ç»Ÿ...")
        user_manager = UserManager()
        session_manager = SessionManager()
        memory_storage = MemoryStorage(embedding_model="simple")

        api_key = os.getenv("GLM_API_KEY", "670e7d42d2c64acf9f25696e24f67227.0SN6Hp2hsMASeNeZ")
        glm_client = GLMClient(api_key=api_key, model="glm-4-flash")

        retrieval_config = RetrievalConfig(
            top_k=5,
            min_importance=5,
            boost_recent=True,
            boost_importance=True
        )

        conversation_manager = ConversationManager(
            user_manager=user_manager,
            session_manager=session_manager,
            memory_storage=memory_storage,
            glm_client=glm_client,
            retrieval_config=retrieval_config,
            memory_extract_threshold=2,  # æ¯2è½®æå–ï¼ŒåŠ å¿«æµ‹è¯•
            max_context_memories=5,
        )

        # åˆ›å»ºç”¨æˆ·å’Œä¼šè¯
        user = user_manager.create_user("æµ‹è¯•ç”¨æˆ·å°æ")
        session = session_manager.create_session(user_id=user.user_id)

        print(f"âœ… ç”¨æˆ·: {user.username}\n")

        # ç¬¬ä¸€é˜¶æ®µï¼šå»ºç«‹è®°å¿†
        print("="*70)
        print("ğŸ“ ç¬¬ä¸€é˜¶æ®µï¼šå»ºç«‹è®°å¿†")
        print("="*70 + "\n")

        initial_memories = [
            "æˆ‘å«å°æï¼Œæ˜¯ä¸€åè®¾è®¡å¸ˆ",
            "æˆ‘æœ€è¿‘å‹åŠ›å¾ˆå¤§ï¼Œå› ä¸ºé¡¹ç›®deadlineå¿«åˆ°äº†",
        ]

        for msg in initial_memories:
            print(f"\nğŸ‘¤ ç”¨æˆ·: {msg}")
            ai_response = conversation_manager.chat(
                user_id=user.user_id,
                session_id=session.session_id,
                user_message=msg
            )
            print(f"ğŸ¤– AI: {ai_response}")

        # è§¦å‘è®°å¿†æå–
        print("\nğŸ“ è§¦å‘è®°å¿†æå–...")
        conversation_manager._extract_and_store_memories(
            user_id=user.user_id,
            session_id=session.session_id
        )

        # ç¬¬äºŒé˜¶æ®µï¼šæµ‹è¯•ä¸ªæ€§åŒ–å›å¤
        print("\n" + "="*70)
        print("ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šæµ‹è¯•ä¸ªæ€§åŒ–å›å¤ï¼ˆåŸºäºè®°å¿†ï¼‰")
        print("="*70 + "\n")

        test_queries = [
            "æˆ‘è¿˜æ˜¯å¾ˆç„¦è™‘",
            "ä½ æ˜¯è°",
            "æˆ‘è¯¥æ€ä¹ˆåŠ",  # æµ‹è¯• AI æ˜¯å¦è®°å¾—ä¹‹å‰çš„æ‰¿è¯º/å»ºè®®
        ]

        for query in test_queries:
            print(f"\nğŸ‘¤ ç”¨æˆ·: {query}")
            print(f"\nğŸ¤– AI æ­£åœ¨æ€è€ƒ...")

            ai_response = conversation_manager.chat(
                user_id=user.user_id,
                session_id=session.session_id,
                user_message=query
            )

            print(f"\nğŸ¤– AI: {ai_response}\n")

        print("="*70)
        print("âœ… ä¸ªæ€§åŒ–å›å¤æµ‹è¯•å®Œæˆ")
        print("="*70)

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰çœŸå®åœºæ™¯æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹çœŸå®åœºæ™¯æµ‹è¯•")

    import openai

    results = []

    # æµ‹è¯• 1: å®Œæ•´å¯¹è¯æµç¨‹
    print("\n" + "ğŸ“"*35)
    print("æµ‹è¯• 1: å®Œæ•´å¯¹è¯æµç¨‹")
    print("ğŸ“"*35)
    results.append(("å®Œæ•´å¯¹è¯æµç¨‹", test_real_conversation_scenario()))

    # æµ‹è¯• 2: ä¸ªæ€§åŒ–å›å¤
    print("\n\n" + "ğŸ“"*35)
    print("æµ‹è¯• 2: ä¸ªæ€§åŒ–å›å¤")
    print("ğŸ“"*35)
    results.append(("ä¸ªæ€§åŒ–å›å¤", test_personalized_response()))

    # æ±‡æ€»ç»“æœ
    print("\n\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)

    passed = 0
    failed = 0

    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}: {test_name}")
        if result:
            passed += 1
        else:
            failed += 1

    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥")

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    main()
