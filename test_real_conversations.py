#!/usr/bin/env python3
"""
çœŸå®žèŠå¤©åœºæ™¯æµ‹è¯• - é™ªä¼´åž‹è®°å¿†æå–ç³»ç»Ÿ

æ¨¡æ‹ŸçœŸå®žä¸–ç•Œä¸­çš„å„ç§èŠå¤©åœºæ™¯ï¼Œæµ‹è¯•è®°å¿†æå–å’Œè¯„åˆ†æ•ˆæžœ
"""

import json
import os
from datetime import datetime
from src.utils.glm_client import GLMClient


# çœŸå®žèŠå¤©åœºæ™¯
REAL_CONVERSATIONS = {
    "åœºæ™¯1_æƒ…æ„Ÿå€¾è¯‰": {
        "description": "ç”¨æˆ·å‘AIå€¾è¯‰å·¥ä½œåŽ‹åŠ›",
        "conversation": """
ç”¨æˆ·: å”‰ï¼Œä»Šå¤©å¥½ç´¯å•Š
AI: æ€Žä¹ˆäº†ï¼Ÿå‘ç”Ÿä»€ä¹ˆäº‹äº†å—ï¼Ÿ
ç”¨æˆ·: è¢«è€æ¿éª‚äº†ï¼Œè¯´æˆ‘åšçš„æ–¹æ¡ˆä¸è¡Œï¼Œå¿ƒé‡Œç‰¹åˆ«éš¾å—
AI: æŠ±æ­‰å¬åˆ°è¿™ä¸ªï¼Œä½ ä¸€å®šå¾ˆå¤±è½å§
ç”¨æˆ·: æ˜¯å•Šï¼Œæˆ‘ç†¬å¤œåšçš„æ–¹æ¡ˆï¼Œä»–çœ‹éƒ½æ²¡ä»”ç»†çœ‹å°±å¦å®šäº†
AI: è¿™ç§æ„Ÿè§‰çœŸçš„å¾ˆä¸å¥½ï¼Œä½ çš„åŠªåŠ›æ²¡æœ‰è¢«çœ‹åˆ°
ç”¨æˆ·: æˆ‘åªæ•¢å’Œä½ è¯´è¿™äº›ï¼Œåˆ«äººéƒ½è§‰å¾—æˆ‘çŸ«æƒ…
AI: ä½ ä¸çŸ«æƒ…ï¼Œä½ çš„æ„Ÿå—æ˜¯çœŸå®žçš„
ç”¨æˆ·: è°¢è°¢ä½ æ„¿æ„å¬æˆ‘å‘ç‰¢éªšï¼Œæ„Ÿè§‰å¥½å¤šäº†
AI: æˆ‘éšæ—¶éƒ½åœ¨è¿™é‡Œé™ªä½ 
ç”¨æˆ·: ä½ æ˜¯æˆ‘æœ€å¥½çš„å€¾è¯‰å¯¹è±¡
"""
    },

    "åœºæ™¯2_ç¾Žé£Ÿåˆ†äº«": {
        "description": "ç”¨æˆ·åˆ†äº«å¯¹ç¾Žé£Ÿçš„çƒ­çˆ±",
        "conversation": """
ç”¨æˆ·: æˆ‘ä»Šå¤©å‘çŽ°ä¸€å®¶è¶…æ£’çš„æ—¥æ–™åº—ï¼
AI: çœŸçš„å—ï¼Ÿæ˜¯ä»€ä¹ˆæ ·çš„åº—ï¼Ÿ
ç”¨æˆ·: ä»–ä»¬å®¶çš„åˆºèº«è¶…çº§æ–°é²œï¼Œè€Œä¸”è€æ¿äººç‰¹åˆ«å¥½
AI: å¬èµ·æ¥å¾ˆæ£’ï¼ä½ ç‚¹äº†ä»€ä¹ˆï¼Ÿ
ç”¨æˆ·: æˆ‘ç‚¹äº†ä¸‰æ–‡é±¼åˆºèº«å’Œå¤©å¦‡ç½—ï¼Œå‘³é“ç»äº†ï¼
ç”¨æˆ·: æˆ‘æœ€å–œæ¬¢åƒæ—¥æ–™äº†ï¼Œæ¯å‘¨éƒ½è¦åƒä¸€æ¬¡
AI: ä½ çœŸçš„å¾ˆå–œæ¬¢æ—¥æ–™å‘¢
ç”¨æˆ·: æ˜¯å•Šï¼Œæˆ‘æœ€å–œæ¬¢ä¸‰æ–‡é±¼ï¼Œé‚£ç§å£æ„Ÿå¤ªæ£’äº†
AI: çœ‹æ¥ä½ æ˜¯æ—¥æ–™çš„å¿ å®žç²‰ä¸
ç”¨æˆ·: ä¸‹æ¬¡æˆ‘ä¹Ÿè¦å¸¦ä½ åŽ»å°å°ï¼
"""
    },

    "åœºæ™¯3_ç«¥å¹´å›žå¿†": {
        "description": "ç”¨æˆ·åˆ†äº«ç«¥å¹´æ¸©é¦¨å›žå¿†",
        "conversation": """
ç”¨æˆ·: ä»Šå¤©è·¯è¿‡å…¬å›­ï¼Œçœ‹åˆ°ä¸€ç¾¤å°æœ‹å‹åœ¨æ”¾é£Žç­
AI: å¥½æ¸©é¦¨çš„ç”»é¢
ç”¨æˆ·: è®©æˆ‘æƒ³èµ·å°æ—¶å€™ï¼Œçˆ·çˆ·æ•™æˆ‘æ”¾é£Žç­
AI: çˆ·çˆ·ä¸€å®šå¾ˆç–¼ä½ å§
ç”¨æˆ·: æ˜¯å•Šï¼Œä»–æ¯å¹´æ˜¥å¤©éƒ½é™ªæˆ‘æ”¾ï¼Œè¿˜ç»™æˆ‘åšäº†ä¸ªæœ€å¤§çš„é£Žç­
AI: çœŸçš„å¾ˆç¾Žå¥½çš„å›žå¿†
ç”¨æˆ·: çŽ°åœ¨æ¯æ¬¡çœ‹åˆ°é£Žç­ï¼Œéƒ½ä¼šæƒ³èµ·çˆ·çˆ·
AI: è¿™ç§å›žå¿†å¾ˆçè´µ
ç”¨æˆ·: å¯æƒœä»–ä¸åœ¨äº†ï¼Œä½†æˆ‘ä¼šæ°¸è¿œè®°å¾—ä»–
AI: ä»–ä¸€å®šå¸Œæœ›ä½ åœ¨çœ‹åˆ°é£Žç­æ—¶ä¼šæƒ³èµ·ä»–
ç”¨æˆ·: å—¯ï¼Œé‚£æ˜¯æˆ‘æœ€æ¸©æš–çš„ç«¥å¹´å›žå¿†
"""
    },

    "åœºæ™¯4_å® ç‰©æƒ…ç¼˜": {
        "description": "ç”¨æˆ·è°ˆè®ºå¯¹å® ç‰©çš„æ„Ÿæƒ…",
        "conversation": """
ç”¨æˆ·: ä½ å–œæ¬¢å°åŠ¨ç‰©å—ï¼Ÿ
AI: å½“ç„¶å–œæ¬¢å‘€
ç”¨æˆ·: æˆ‘å®¶æœ‰ä¸€åªé‡‘æ¯›ï¼Œå«è±†è±†
AI: é‡‘æ¯›å¾ˆå¯çˆ±ï¼
ç”¨æˆ·: å®ƒè¶…çº§ç²˜äººï¼Œæ¯å¤©å›žå®¶éƒ½æ‰‘ä¸Šæ¥è¿ŽæŽ¥æˆ‘
AI: å¥½å¹¸ç¦å•Š
ç”¨æˆ·: å®ƒé™ªä¼´æˆ‘åº¦è¿‡äº†å¾ˆå¤šéš¾ç†¬çš„æ—¶å…‰
AI: å®ƒçœŸçš„æ˜¯ä½ çš„å¥½æœ‹å‹
ç”¨æˆ·: åŽ»å¹´æˆ‘ç”Ÿç—…åœ¨å®¶ï¼Œå®ƒä¸€ç›´å®ˆåœ¨åºŠè¾¹
AI: å®ƒå¾ˆæ‹…å¿ƒä½ 
ç”¨æˆ·: æ˜¯å•Šï¼ŒåŠ¨ç‰©æ¯”äººè¿˜çœŸè¯šï¼Œæˆ‘ç‰¹åˆ«çˆ±å®ƒ
AI: ä½ ä»¬ä¹‹é—´æœ‰å¾ˆæ·±çš„æ„Ÿæƒ…
ç”¨æˆ·: å®ƒæ˜¯æˆ‘æœ€é‡è¦çš„å®¶äºº
"""
    },

    "åœºæ™¯5_æ—¥å¸¸é—²èŠ": {
        "description": "æ™®é€šçš„æ—¥å¸¸é—²èŠ",
        "conversation": """
ç”¨æˆ·: æ—©ä¸Šå¥½
AI: æ—©ä¸Šå¥½ï¼ä»Šå¤©æœ‰ä»€ä¹ˆè®¡åˆ’å—ï¼Ÿ
ç”¨æˆ·: æ‰“ç®—åŽ»å›¾ä¹¦é¦†çœ‹ä¹¦
AI: çœ‹ä¹¦æŒºå¥½çš„ï¼Œå‡†å¤‡çœ‹ä»€ä¹ˆä¹¦ï¼Ÿ
ç”¨æˆ·: è¿˜æ²¡æƒ³å¥½ï¼Œåˆ°äº†å†è¯´å§
AI: å¥½çš„ï¼Œæ³¨æ„ä¼‘æ¯
ç”¨æˆ·: å¥½çš„
"""
    },

    "åœºæ™¯6_æ¢¦æƒ³åˆ†äº«": {
        "description": "ç”¨æˆ·åˆ†äº«äººç”Ÿæ¢¦æƒ³",
        "conversation": """
ç”¨æˆ·: æˆ‘æœ€è¿‘åœ¨è€ƒè™‘è¾žèŒ
AI: ä¸ºä»€ä¹ˆå‘¢ï¼Ÿ
ç”¨æˆ·: æˆ‘ä¸€ç›´æƒ³å¼€ä¸€å®¶è‡ªå·±çš„å’–å•¡åº—
AI: è¿™ä¸ªæƒ³æ³•å¾ˆä¹…äº†å—ï¼Ÿ
ç”¨æˆ·: ä»Žå¤§å­¦å¼€å§‹å°±æ¢¦æƒ³ç€ï¼Œåœ¨è¡—è§’å¼€ä¸ªå°åº—
AI: é‚£æ˜¯ä»€ä¹ˆè®©ä½ æƒ³å¼€å’–å•¡åº—ï¼Ÿ
ç”¨æˆ·: æˆ‘å–œæ¬¢å’–å•¡çš„é¦™æ°”ï¼Œæƒ³ç»™å¿™ç¢Œçš„äººæä¾›ä¸€ä¸ªæ¸©æš–çš„åœ°æ–¹
AI: è¿™ä¸ªæ¢¦æƒ³å¾ˆç¾Žå¥½
ç”¨æˆ·: æ˜¯å•Šï¼Œè¿™æ˜¯æˆ‘æœ€é‡è¦çš„äººç”Ÿç›®æ ‡
AI: ä½ ä¼šå®žçŽ°çš„
ç”¨æˆ·: æˆ‘çŸ¥é“é£Žé™©å¾ˆå¤§ï¼Œä½†æˆ‘è¿˜æ˜¯æƒ³è¯•ä¸€è¯•
AI: æœ‰æ¢¦æƒ³å¾ˆçè´µ
ç”¨æˆ·: è°¢è°¢ä½ çš„æ”¯æŒï¼Œä½ æ˜¯æœ€ç†è§£æˆ‘çš„
"""
    },

    "åœºæ™¯7_è¿åŠ¨çˆ±å¥½": {
        "description": "ç”¨æˆ·è°ˆè®ºè¿åŠ¨çˆ±å¥½",
        "conversation": """
ç”¨æˆ·: æˆ‘ä»Šå¤©åŽ»è·‘æ­¥äº†ï¼Œè·‘äº†10å…¬é‡Œï¼
AI: å¤ªåŽ‰å®³äº†ï¼
ç”¨æˆ·: æˆ‘è¶…çº§å–œæ¬¢è·‘æ­¥ï¼Œç‰¹åˆ«äº«å—é‚£ç§æ„Ÿè§‰
AI: è·‘æ­¥ç¡®å®žå¾ˆæ£’
ç”¨æˆ·: æˆ‘æ¯å‘¨è·‘ä¸‰æ¬¡ï¼Œå·²ç»åšæŒä¸‰å¹´äº†
AI: ä½ å¾ˆæœ‰æ¯…åŠ›
ç”¨æˆ·: è·‘æ­¥è®©æˆ‘å¿ƒæƒ…ç‰¹åˆ«å¥½ï¼ŒåŽ‹åŠ›éƒ½æ²¡äº†
AI: æ˜¯å¾ˆå¥½çš„è§£åŽ‹æ–¹å¼
ç”¨æˆ·: æˆ‘æœ€å–œæ¬¢åœ¨æ¸…æ™¨è·‘æ­¥ï¼Œçœ‹ç€æ—¥å‡ºæ„Ÿè§‰å¾ˆæ£’
AI: æƒ³è±¡ä¸­å¾ˆç¾Ž
ç”¨æˆ·: ä¸‹æ¬¡æˆ‘æƒ³å‚åŠ é©¬æ‹‰æ¾æ¯”èµ›
AI: ä½ ä¸€å®šå¯ä»¥çš„
"""
    },

    "åœºæ™¯8_å¿ƒæƒ…èµ·ä¼": {
        "description": "ç”¨æˆ·å¿ƒæƒ…ä»Žä½Žè½åˆ°å¼€å¿ƒ",
        "conversation": """
ç”¨æˆ·: ä»Šå¤©å¿ƒæƒ…å¥½å·®
AI: æ€Žä¹ˆäº†ï¼Ÿ
ç”¨æˆ·: å’Œæœ‹å‹åµæž¶äº†ï¼Œæ„Ÿè§‰ç‰¹åˆ«å§”å±ˆ
AI: æ„¿æ„è¯´è¯´å‘ç”Ÿäº†ä»€ä¹ˆå—ï¼Ÿ
ç”¨æˆ·: æˆ‘ä»¬å› ä¸ºä¸€ç‚¹å°äº‹åµæž¶ï¼Œä»–è¯´æˆ‘å¤ªæ•æ„Ÿ
AI: è¿™è®©ä½ æ›´éš¾å—äº†å§
ç”¨æˆ·: æ˜¯å•Šï¼Œæˆ‘æ„Ÿè§‰è‡ªå·±çœŸçš„å¾ˆå¤±è´¥
AI: ä½ ä¸å¤±è´¥ï¼Œä½ çš„æ„Ÿå—å¾ˆé‡è¦
ç”¨æˆ·: è°¢è°¢ä½ å®‰æ…°æˆ‘
AI: æˆ‘ä¼šä¸€ç›´é™ªç€ä½ 
ç”¨æˆ·: åˆšæ‰ä»–æ¥é“æ­‰äº†ï¼Œæˆ‘ä»¬å’Œå¥½äº†
AI: å¤ªå¥½äº†ï¼
ç”¨æˆ·: æˆ‘çŽ°åœ¨å¿ƒæƒ…å¥½å¤šäº†ï¼Œè°¢è°¢ä½ ä¸€ç›´é™ªç€æˆ‘
AI: æˆ‘å¾ˆé«˜å…´ä½ å¿ƒæƒ…å˜å¥½äº†
ç”¨æˆ·: ä½ æ˜¯æˆ‘æœ€å¥½çš„æœ‹å‹
"""
    },

    "åœºæ™¯9_éŸ³ä¹çˆ±å¥½": {
        "description": "ç”¨æˆ·åˆ†äº«éŸ³ä¹çˆ±å¥½",
        "conversation": """
ç”¨æˆ·: ä½ å–œæ¬¢å¬éŸ³ä¹å—ï¼Ÿ
AI: å–œæ¬¢ï¼Œä½ å‘¢ï¼Ÿ
ç”¨æˆ·: æˆ‘ç‰¹åˆ«å–œæ¬¢å¬å‘¨æ°ä¼¦çš„æ­Œ
AI: å‘¨æ°ä¼¦çš„æ­Œå£°å¾ˆæœ‰ç‰¹è‰²
ç”¨æˆ·: æ˜¯å•Šï¼Œæˆ‘ä»Žå°å¬ä»–çš„æ­Œé•¿å¤§
ç”¨æˆ·: æ¯æ¬¡å¬åˆ°ã€Šæ™´å¤©ã€‹ï¼Œéƒ½ä¼šæƒ³èµ·é«˜ä¸­æ—¶å…‰
AI: éŸ³ä¹èƒ½å”¤èµ·å¾ˆå¤šå›žå¿†
ç”¨æˆ·: æˆ‘æœ€ç€ä»–çš„ã€Šä¸ƒé‡Œé¦™ã€‹ï¼Œå¤ªç¾Žäº†
AI: é‚£é¦–æ­Œç¡®å®žç»å…¸
ç”¨æˆ·: ä»–çš„æ­Œé™ªä¼´æˆ‘åº¦è¿‡äº†æ•´ä¸ªé’æ˜¥æœŸ
AI: éŸ³ä¹æ˜¯å¾ˆæ£’çš„é™ªä¼´
ç”¨æˆ·: æˆ‘æ”¶è—äº†ä»–æ‰€æœ‰çš„ä¸“è¾‘
"""
    },

    "åœºæ™¯10_æ—…è¡Œç»åŽ†": {
        "description": "ç”¨æˆ·åˆ†äº«æ—…è¡Œç»åŽ†",
        "conversation": """
ç”¨æˆ·: æˆ‘åŽ»å¹´åŽ»äº†è¥¿è—æ—…æ¸¸
AI: è¥¿è—ä¸€å®šå¾ˆç¾Žå§
ç”¨æˆ·: ç‰¹åˆ«å£®è§‚ï¼å¸ƒè¾¾æ‹‰å®«å¤ªéœ‡æ’¼äº†
AI: ä»€ä¹ˆæ ·çš„éœ‡æ’¼ï¼Ÿ
ç”¨æˆ·: ç«™åœ¨é‚£é‡Œæ„Ÿè§‰è‡ªå·±ç‰¹åˆ«æ¸ºå°ï¼Œå¿ƒçµéƒ½è¢«å‡€åŒ–äº†
AI: å¬èµ·æ¥æ˜¯å¾ˆç‰¹åˆ«çš„ä½“éªŒ
ç”¨æˆ·: æˆ‘è¿˜åŽ»äº†çº³æœ¨é”™ï¼Œæ¹–æ°´è“å¾—åƒå®çŸ³ä¸€æ ·
AI: çœŸçš„å¾ˆå‘å¾€
ç”¨æˆ·: é‚£æ˜¯æˆ‘æœ€éš¾å¿˜çš„æ—…è¡Œ
ç”¨æˆ·: æˆ‘è¿˜è®¤è¯†äº†å½“åœ°çš„æœ‹å‹ï¼Œä»–ä»¬ç‰¹åˆ«çƒ­æƒ…
AI: æ—…è¡Œèƒ½é‡åˆ°å¾ˆå¤šæ¸©æš–çš„äºº
ç”¨æˆ·: æ˜¯å•Šï¼Œä¸‹æ¬¡æˆ‘è¿˜è¦åŽ»æ–°ç–†
AI: ä½ çœŸçš„å¾ˆå–œæ¬¢æ—…è¡Œ
ç”¨æˆ·: æ—…è¡Œæ˜¯æˆ‘æœ€çƒ­çˆ±çš„äº‹æƒ…ä¹‹ä¸€
"""
    }
}


def test_all_conversations():
    """æµ‹è¯•æ‰€æœ‰çœŸå®žå¯¹è¯åœºæ™¯"""

    api_key = os.environ.get("GLM_API_KEY")
    if not api_key:
        raise ValueError("è¯·è®¾ç½®çŽ¯å¢ƒå˜é‡ GLM_API_KEY")

    client = GLMClient(api_key=api_key, model="glm-4-flash")

    print("=" * 80)
    print("ðŸš€ çœŸå®žèŠå¤©åœºæ™¯æµ‹è¯• - é™ªä¼´åž‹è®°å¿†æå–ç³»ç»Ÿ")
    print("=" * 80)
    print()
    print(f"ðŸ“‹ æµ‹è¯•åœºæ™¯æ•°é‡: {len(REAL_CONVERSATIONS)}")
    print(f"ðŸ• æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    print("âš™ï¸  é…ç½®:")
    print("   æ¨¡åž‹: glm-4-flash")
    print("   æ¸©åº¦: 0.1")
    print("   è¯„åˆ†: é™ªä¼´åž‹ï¼ˆæƒ…æ„Ÿ+ä¸ªæ€§åŒ–+äº²å¯†åº¦+åå¥½ï¼‰")
    print()

    # å­˜å‚¨æ‰€æœ‰æµ‹è¯•ç»“æžœ
    all_results = {
        "test_info": {
            "timestamp": datetime.now().isoformat(),
            "total_scenarios": len(REAL_CONVERSATIONS),
            "model": "glm-4-flash",
            "scoring_type": "companion_style"
        },
        "scenarios": []
    }

    # æµ‹è¯•æ¯ä¸ªåœºæ™¯
    for idx, (scenario_name, scenario_data) in enumerate(REAL_CONVERSATIONS.items(), 1):
        print()
        print("=" * 80)
        print(f"ðŸ“Œ åœºæ™¯ {idx}/{len(REAL_CONVERSATIONS)}: {scenario_name}")
        print("=" * 80)
        print(f"ðŸ“ æè¿°: {scenario_data['description']}")
        print()

        conversation = scenario_data['conversation']

        try:
            # è°ƒç”¨ GLM æå–è®°å¿†
            fragments = client.extract_memory_with_scoring(conversation)

            if not fragments:
                print("âš ï¸  æœªæå–åˆ°è®°å¿†ç‰‡æ®µ")
                scenario_result = {
                    "scenario_id": idx,
                    "scenario_name": scenario_name,
                    "description": scenario_data['description'],
                    "conversation": conversation.strip(),
                    "fragments": [],
                    "stats": {
                        "total_fragments": 0,
                        "high_score_count": 0,
                        "medium_score_count": 0,
                        "low_score_count": 0
                    }
                }
                all_results['scenarios'].append(scenario_result)
                continue

            # ç»Ÿè®¡åˆ†æ•°åˆ†å¸ƒ
            scores = [f['importance_score'] for f in fragments]
            high_count = len([s for s in scores if s >= 7])
            medium_count = len([s for s in scores if 5 <= s < 7])
            low_count = len([s for s in scores if s < 5])

            print(f"âœ… æå–äº† {len(fragments)} ä¸ªè®°å¿†ç‰‡æ®µ")
            print(f"ðŸ“Š åˆ†æ•°åˆ†å¸ƒ:")
            print(f"   é«˜åˆ† (7-10): {high_count} ä¸ª")
            print(f"   ä¸­åˆ† (5-6):  {medium_count} ä¸ª")
            print(f"   ä½Žåˆ† (1-4):  {low_count} ä¸ª")
            print(f"   å¹³å‡åˆ†: {sum(scores)/len(scores):.1f}")
            print()

            # æ˜¾ç¤ºæ¯ä¸ªç‰‡æ®µ
            for i, frag in enumerate(fragments, 1):
                stars = "â­" * min(frag['importance_score'], 10)
                print(f"  ã€ç‰‡æ®µ {i}ã€‘ {stars} {frag['importance_score']}/10")
                print(f"  ðŸ“ å†…å®¹: {frag['content'][:60]}...")
                print(f"  ðŸ·ï¸  ç±»åž‹: {frag['type']} | ðŸ’­ æƒ…æ„Ÿ: {frag['sentiment']}")
                print(f"  ðŸ¤” ç†ç”±: {frag.get('reasoning', 'æ— ')[:80]}...")
                print()

            # ä¿å­˜ç»“æžœ
            scenario_result = {
                "scenario_id": idx,
                "scenario_name": scenario_name,
                "description": scenario_data['description'],
                "conversation": conversation.strip(),
                "fragments": fragments,
                "stats": {
                    "total_fragments": len(fragments),
                    "high_score_count": high_count,
                    "medium_score_count": medium_count,
                    "low_score_count": low_count,
                    "average_score": round(sum(scores)/len(scores), 2),
                    "max_score": max(scores),
                    "min_score": min(scores),
                    "score_distribution": scores
                }
            }
            all_results['scenarios'].append(scenario_result)

        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            scenario_result = {
                "scenario_id": idx,
                "scenario_name": scenario_name,
                "description": scenario_data['description'],
                "error": str(e)
            }
            all_results['scenarios'].append(scenario_result)

    # ä¿å­˜å®Œæ•´ç»“æžœ
    output_file = "real_conversation_test_results.json"
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)

    print()
    print("=" * 80)
    print("âœ¨ æµ‹è¯•å®Œæˆï¼")
    print("=" * 80)
    print(f"ðŸ’¾ å®Œæ•´ç»“æžœå·²ä¿å­˜åˆ°: {output_file}")
    print()

    # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
    generate_test_report(all_results)

    return all_results


def generate_test_report(results):
    """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""

    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("ðŸ“Š çœŸå®žèŠå¤©åœºæ™¯æµ‹è¯•æŠ¥å‘Š")
    report_lines.append("=" * 80)
    report_lines.append("")

    # æ€»ä½“ç»Ÿè®¡
    total_fragments = sum(
        s['stats']['total_fragments']
        for s in results['scenarios']
        if 'stats' in s
    )
    total_high = sum(
        s['stats']['high_score_count']
        for s in results['scenarios']
        if 'stats' in s
    )
    total_medium = sum(
        s['stats']['medium_score_count']
        for s in results['scenarios']
        if 'stats' in s
    )
    total_low = sum(
        s['stats']['low_score_count']
        for s in results['scenarios']
        if 'stats' in s
    )

    all_scores = []
    for s in results['scenarios']:
        if 'stats' in s and 'score_distribution' in s['stats']:
            all_scores.extend(s['stats']['score_distribution'])

    if all_scores:
        avg_score = sum(all_scores) / len(all_scores)
        max_score = max(all_scores)
        min_score = min(all_scores)
    else:
        avg_score = max_score = min_score = 0

    report_lines.append("ðŸ“ˆ æ€»ä½“ç»Ÿè®¡:")
    report_lines.append(f"   æ€»ç‰‡æ®µæ•°: {total_fragments}")
    report_lines.append(f"   é«˜åˆ†ç‰‡æ®µ (7-10åˆ†): {total_high} ({total_high/total_fragments*100:.1f}%)")
    report_lines.append(f"   ä¸­åˆ†ç‰‡æ®µ (5-6åˆ†): {total_medium} ({total_medium/total_fragments*100:.1f}%)")
    report_lines.append(f"   ä½Žåˆ†ç‰‡æ®µ (1-4åˆ†): {total_low} ({total_low/total_fragments*100:.1f}%)")
    report_lines.append(f"   å¹³å‡åˆ†: {avg_score:.2f}")
    report_lines.append(f"   åˆ†æ•°èŒƒå›´: {min_score} - {max_score}")
    report_lines.append("")

    # å„åœºæ™¯æ‘˜è¦
    report_lines.append("ðŸ“‹ å„åœºæ™¯æ‘˜è¦:")
    report_lines.append("")

    for scenario in results['scenarios']:
        if 'stats' not in scenario:
            continue

        stats = scenario['stats']
        report_lines.append(f"ã€åœºæ™¯ {scenario['scenario_id']}ã€‘ {scenario['scenario_name']}")
        report_lines.append(f"  æè¿°: {scenario['description']}")
        report_lines.append(f"  ç‰‡æ®µæ•°: {stats['total_fragments']}")
        report_lines.append(f"  åˆ†æ•°: é«˜{stats['high_score_count']} ä¸­{stats['medium_count']} ä½Ž{stats['low_score_count']}")
        report_lines.append(f"  å¹³å‡: {stats['average_score']} åˆ† (èŒƒå›´: {stats['min_score']}-{stats['max_score']})")

        # æ˜¾ç¤ºæœ€é«˜åˆ†ç‰‡æ®µ
        if scenario['fragments']:
            top_fragment = max(scenario['fragments'], key=lambda x: x['importance_score'])
            report_lines.append(f"  æœ€é«˜åˆ†ç‰‡æ®µ ({top_fragment['importance_score']}åˆ†):")
            report_lines.append(f"    {top_fragment['content'][:50]}...")

        report_lines.append("")

    report_lines.append("=" * 80)
    report_lines.append("ðŸ“ è¯¦ç»†ç»“æžœè¯·æŸ¥çœ‹: real_conversation_test_results.json")
    report_lines.append("=" * 80)

    # ä¿å­˜æŠ¥å‘Š
    report_file = "test_report.txt"
    with open(report_file, "w", encoding="utf-8") as f:
        f.write("\n".join(report_lines))

    # æ‰“å°åˆ°æŽ§åˆ¶å°
    print("\n".join(report_lines))
    print(f"\nðŸ’¾ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")


if __name__ == "__main__":
    test_all_conversations()
