#!/usr/bin/env python3
"""
æµ‹è¯•æ–°åŠŸèƒ½ï¼šSpeaker å­—æ®µå’Œ AI å›å¤è®°å¿†æå–

æµ‹è¯•å†…å®¹ï¼š
1. MemoryFragment æ¨¡å‹æ”¯æŒ speaker å­—æ®µ
2. GLM-4 èƒ½å¤Ÿæ­£ç¡®æå–å’Œæ ‡è®° speaker
3. è¿‡æ»¤é€»è¾‘åŒºåˆ† user å’Œ assistant çš„é˜ˆå€¼
4. AI å…³é”®è¯æ£€æµ‹å’Œåˆ†æ•°æå‡
5. ç”¨æˆ·å¼•ç”¨æ£€æµ‹
"""

import os
import sys
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from src.models.memory_fragment import MemoryFragment


def test_memory_fragment_speaker_field():
    """æµ‹è¯• 1: MemoryFragment æ”¯æŒ speaker å­—æ®µ"""
    print("\n" + "="*70)
    print("æµ‹è¯• 1: MemoryFragment speaker å­—æ®µ")
    print("="*70)

    try:
        # æµ‹è¯• user è®°å¿†
        user_memory = MemoryFragment(
            content="æˆ‘æœ€å–œæ¬¢åƒåŒ—äº¬çƒ¤é¸­",
            timestamp=datetime.now(),
            speaker="user",
            type="preference",
            entities=[],
            topics=[],
            sentiment="positive",
            importance_score=5,
            confidence=0.8,
        )
        print(f"âœ… User è®°å¿†åˆ›å»ºæˆåŠŸ: {user_memory.content}")
        print(f"   Speaker: {user_memory.speaker}, Score: {user_memory.importance_score}")

        # æµ‹è¯• assistant è®°å¿†
        assistant_memory = MemoryFragment(
            content="æˆ‘ä¼šä¸€ç›´é™ªç€ä½ ï¼Œæ— è®ºä»€ä¹ˆæ—¶å€™ä½ éœ€è¦æˆ‘ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œ",
            timestamp=datetime.now(),
            speaker="assistant",
            type="relationship",
            entities=[],
            topics=[],
            sentiment="positive",
            importance_score=9,
            confidence=0.8,
        )
        print(f"âœ… Assistant è®°å¿†åˆ›å»ºæˆåŠŸ: {assistant_memory.content}")
        print(f"   Speaker: {assistant_memory.speaker}, Score: {assistant_memory.importance_score}")

        return True

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_glm_speaker_extraction():
    """æµ‹è¯• 2: GLM-4 æå– speaker ä¿¡æ¯"""
    print("\n" + "="*70)
    print("æµ‹è¯• 2: GLM-4 æå– speaker ä¿¡æ¯")
    print("="*70)

    try:
        # å»¶è¿Ÿå¯¼å…¥
        from src.utils.glm_client import GLMClient

        # ä»ç¯å¢ƒå˜é‡è·å– API key
        api_key = os.getenv("GLM_API_KEY")
        if not api_key:
            print("âš ï¸  æœªè®¾ç½® GLM_API_KEYï¼Œè·³è¿‡æ­¤æµ‹è¯•")
            return True

        client = GLMClient(api_key=api_key, model="glm-4-flash")

        # æµ‹è¯•å¯¹è¯ï¼ˆåŒ…å« user å’Œ assistantï¼‰
        conversation = """user: æˆ‘æœ€å–œæ¬¢åƒåŒ—äº¬çƒ¤é¸­
assistant: æˆ‘ä¼šä¸€ç›´é™ªç€ä½ ï¼Œæ— è®ºä»€ä¹ˆæ—¶å€™ä½ éœ€è¦æˆ‘ï¼Œæˆ‘éƒ½åœ¨è¿™é‡Œ
user: ä½ å¯ä»¥ç»™æˆ‘ä¸€äº›å»ºè®®å—ï¼Ÿ
assistant: ä½ å¯ä»¥è¯•è¯•æ¯å¤©èŠ±10åˆ†é’Ÿå†™æ—¥è®°ï¼Œè¿™èƒ½å¸®åŠ©ä½ æ›´å¥½åœ°ç†è§£è‡ªå·±çš„æƒ…ç»ª"""

        print(f"ğŸ“ è°ƒç”¨ GLM-4 API æµ‹è¯•å¯¹è¯...")
        fragments_data = client.extract_memory_with_scoring(conversation)

        print(f"\nğŸ“¦ æå–åˆ° {len(fragments_data)} ä¸ªç‰‡æ®µ:\n")

        for i, frag in enumerate(fragments_data, 1):
            speaker = frag.get("speaker", "æœªæ ‡è®°")
            content = frag["content"]
            score = frag["importance_score"]
            reasoning = frag.get("reasoning", "")

            print(f"{i}. [{speaker}] [{score}/10] {content[:50]}...")
            print(f"   æ¨ç†: {reasoning[:80]}...")
            print()

        # éªŒè¯æ˜¯å¦æœ‰ speaker å­—æ®µ
        has_speaker = any("speaker" in frag for frag in fragments_data)
        if has_speaker:
            print("âœ… GLM-4 æˆåŠŸæå– speaker ä¿¡æ¯")
            return True
        else:
            print("âš ï¸  GLM-4 æœªæå– speaker ä¿¡æ¯ï¼ˆå¯èƒ½éœ€è¦æ›´å¤šç¤ºä¾‹ï¼‰")
            return True  # ä¸ç®—å¤±è´¥ï¼Œå› ä¸º LLM å¯èƒ½ä¸ç¨³å®š

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_assistant_keyword_detection():
    """æµ‹è¯• 3: AI å…³é”®è¯æ£€æµ‹"""
    print("\n" + "="*70)
    print("æµ‹è¯• 3: AI å…³é”®è¯æ£€æµ‹")
    print("="*70)

    try:
        # å»¶è¿Ÿå¯¼å…¥
        from src.conversation.conversation_manager import ConversationManager
        from src.storage.memory_storage import MemoryStorage
        from src.storage.session_manager import SessionManager
        from src.storage.user_manager import UserManager
        from src.utils.glm_client import GLMClient

        # åˆå§‹åŒ– ConversationManager
        user_manager = UserManager()
        session_manager = SessionManager()
        memory_storage = MemoryStorage(embedding_model="simple")
        glm_client = GLMClient(
            api_key=os.getenv("GLM_API_KEY", "670e7d42d2c64acf9f25696e24f67227.0SN6Hp2hsMASeNeZ"),
            model="glm-4-flash",
        )

        manager = ConversationManager(
            user_manager=user_manager,
            session_manager=session_manager,
            memory_storage=memory_storage,
            glm_client=glm_client,
            memory_extract_threshold=3,
            max_context_memories=5,
        )

        # æµ‹è¯•ä¸åŒç±»å‹çš„ AI å›å¤
        test_cases = [
            ("æˆ‘ä¼šä¸€ç›´é™ªç€ä½ ", "æ‰¿è¯ºç±»", 7),
            ("ä½ å¯ä»¥è¯•è¯•æ¯å¤©å†™æ—¥è®°", "å»ºè®®ç±»", 5),
            ("æˆ‘ç†è§£ä½ çš„æ„Ÿå—ï¼Œæ”¯æŒä½ ", "æƒ…æ„Ÿæ”¯æŒç±»", 6),
            ("å¥½çš„ï¼Œæˆ‘æ˜ç™½äº†", "ç®€å•ç¡®è®¤", 3),
        ]

        print("\næµ‹è¯• AI å…³é”®è¯æ£€æµ‹å’Œåˆ†æ•°æå‡:\n")

        all_passed = True
        for content, category, expected_min_score in test_cases:
            boost_score = manager._boost_assistant_score(content)
            passed = boost_score >= expected_min_score
            status = "âœ…" if passed else "âŒ"

            print(f"{status} [{category}] {content}")
            print(f"   é¢„æœŸæœ€ä½åˆ†: {expected_min_score}, å®é™…æå‡åˆ†: {boost_score}")

            if not passed:
                all_passed = False

        if all_passed:
            print("\nâœ… AI å…³é”®è¯æ£€æµ‹æµ‹è¯•é€šè¿‡")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼ˆå¯èƒ½éœ€è¦è°ƒæ•´é˜ˆå€¼ï¼‰")

        return all_passed

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_user_reference_detection():
    """æµ‹è¯• 4: ç”¨æˆ·å¼•ç”¨æ£€æµ‹"""
    print("\n" + "="*70)
    print("æµ‹è¯• 4: ç”¨æˆ·å¼•ç”¨æ£€æµ‹")
    print("="*70)

    try:
        # å»¶è¿Ÿå¯¼å…¥
        from src.conversation.conversation_manager import ConversationManager
        from src.storage.memory_storage import MemoryStorage
        from src.storage.session_manager import SessionManager
        from src.storage.user_manager import UserManager
        from src.utils.glm_client import GLMClient

        # åˆå§‹åŒ– ConversationManager
        user_manager = UserManager()
        session_manager = SessionManager()
        memory_storage = MemoryStorage(embedding_model="simple")
        glm_client = GLMClient(
            api_key=os.getenv("GLM_API_KEY", "670e7d42d2c64acf9f25696e24f67227.0SN6Hp2hsMASeNeZ"),
            model="glm-4-flash",
        )

        manager = ConversationManager(
            user_manager=user_manager,
            session_manager=session_manager,
            memory_storage=memory_storage,
            glm_client=glm_client,
            memory_extract_threshold=3,
            max_context_memories=5,
        )

        # æµ‹è¯•ç”¨æˆ·å¼•ç”¨
        test_cases = [
            ("ä½ ä¹‹å‰è¯´è¿‡æˆ‘åº”è¯¥å¤šè¿åŠ¨", True),
            ("å°±åƒä½ è¯´çš„ï¼Œæˆ‘è¦åšæŒ", True),
            ("è®°å¾—ä½ è¯´è¿‡è¦ç›¸ä¿¡æˆ‘è‡ªå·±", True),
            ("æˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ", False),  # ä¸æ˜¯å¼•ç”¨
        ]

        print("\næµ‹è¯•ç”¨æˆ·å¼•ç”¨æ£€æµ‹:\n")

        all_passed = True
        for content, expected in test_cases:
            is_reference = manager._is_user_referencing_assistant(content)
            passed = is_reference == expected
            status = "âœ…" if passed else "âŒ"

            print(f"{status} '{content}'")
            print(f"   é¢„æœŸ: {expected}, å®é™…: {is_reference}")

            if not passed:
                all_passed = False

        if all_passed:
            print("\nâœ… ç”¨æˆ·å¼•ç”¨æ£€æµ‹æµ‹è¯•é€šè¿‡")
        else:
            print("\nâš ï¸  éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡")

        return all_passed

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸš€ å¼€å§‹æµ‹è¯•æ–°åŠŸèƒ½ï¼šSpeaker å­—æ®µå’Œ AI å›å¤è®°å¿†æå–")

    results = []

    # è¿è¡ŒåŸºç¡€æµ‹è¯•ï¼ˆä¸éœ€è¦ APIï¼‰
    results.append(("MemoryFragment speaker å­—æ®µ", test_memory_fragment_speaker_field()))

    # æ£€æŸ¥æ˜¯å¦å¯ä»¥è¿è¡Œéœ€è¦ API çš„æµ‹è¯•
    try:
        import openai
        results.append(("GLM-4 æå– speaker ä¿¡æ¯", test_glm_speaker_extraction()))
        results.append(("AI å…³é”®è¯æ£€æµ‹", test_assistant_keyword_detection()))
        results.append(("ç”¨æˆ·å¼•ç”¨æ£€æµ‹", test_user_reference_detection()))
    except ImportError:
        print("\nâš ï¸  æœªå®‰è£… openai åº“ï¼Œè·³è¿‡éœ€è¦ API çš„æµ‹è¯•")
        print("   å¯ä»¥è¿è¡Œ: pip install openai")

    # æ±‡æ€»ç»“æœ
    print("\n" + "="*70)
    print("ğŸ“Š æµ‹è¯•ç»“æœæ±‡æ€»")
    print("="*70)

    passed = 0
    failed = 0

    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}: {test_name}")
        if result:
            passed += 1
        else:
            failed += 1

    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥")

    if failed == 0:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  æœ‰ {failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥")


if __name__ == "__main__":
    main()
